
@incollection{mcbride_i_2016,
	address = {Cham},
	title = {I {Got} {Plenty} o’ {Nuttin}’},
	volume = {9600},
	isbn = {978-3-319-30935-4 978-3-319-30936-1},
	abstract = {Work to date on combining linear types and dependent types has deliberately and successfully avoided doing so. Entirely ﬁt for their own purposes, such systems wisely insist that types depend only on the replicable sublanguage, thus sidestepping the issue of counting uses of limited-use data either within types or in ways which are only really needed to shut the typechecker up. As a result, the linear implication (‘lollipop’) stubbornly remains a non-dependent S T . This paper deﬁnes and establishes the basic metatheory of a type theory supporting a ‘dependent lollipop’ (x : S) T [x], where what the input used to be is in some way commemorated by the type of the output. For example, we might convert list to length-indexed vectors in place by a function with type (l : List X) Vector X (length l). Usage is tracked with resource annotations belonging to an arbitrary rig, or ‘riNg without Negation’. The key insight is to use the rig’s zero to mark information in contexts which is present for purposes of contemplation rather than consumption, like a meal we remember fondly but cannot eat twice. We need no runtime copies of l to form the above vector type. We can have plenty of nothing with no additional runtime resource, and nothing is plenty for the construction of dependent types.},
	language = {en},
	urldate = {2022-04-27},
	booktitle = {A {List} of {Successes} {That} {Can} {Change} the {World}},
	publisher = {Springer International Publishing},
	author = {McBride, Conor},
	year = {2016},
	doi = {10.1007/978-3-319-30936-1_12},
	note = {Series Title: Lecture Notes in Computer Science},
	pages = {207--233},
	file = {McBride - 2016 - I Got Plenty o’ Nuttin’.pdf:C\:\\Users\\mhuisi\\Zotero\\storage\\3LHEYVMF\\McBride - 2016 - I Got Plenty o’ Nuttin’.pdf:application/pdf},
}

@article{brady_idris_2021,
	title = {Idris 2: {Quantitative} {Type} {Theory} in {Practice}},
	shorttitle = {Idris 2},
	abstract = {Dependent types allow us to express precisely what a function is intended to do. Recent work on Quantitative Type Theory (QTT) extends dependent type systems with linearity, also allowing precision in expressing when a function can run. This is promising, because it suggests the ability to design and reason about resource usage protocols, such as we might find in distributed and concurrent programming, where the state of a communication channel changes throughout program execution. As yet, however, there has not been a full-scale programming language with which to experiment with these ideas. Idris 2 is a new version of the dependently typed language Idris, with a new core language based on QTT, supporting linear and dependent types. In this paper, we introduce Idris 2, and describe how QTT has influenced its design. We give examples of the benefits of QTT in practice including: expressing which data is erased at run time, at the type level; and, resource tracking in the type system leading to type-safe concurrent programming with session types.},
	journal = {arXiv:2104.00480 [cs]},
	author = {Brady, Edwin},
	month = apr,
	year = {2021},
	keywords = {Computer Science - Programming Languages},
	file = {arXiv Fulltext PDF:C\:\\Users\\mhuisi\\Zotero\\storage\\7HZ2TMBU\\Brady - 2021 - Idris 2 Quantitative Type Theory in Practice.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\mhuisi\\Zotero\\storage\\5Y6PCTDH\\2104.html:text/html},
}

@inproceedings{atkey_syntax_2018,
	address = {Oxford United Kingdom},
	title = {Syntax and {Semantics} of {Quantitative} {Type} {Theory}},
	isbn = {978-1-4503-5583-4},
	doi = {10.1145/3209108.3209189},
	abstract = {We present Quantitative Type Theory, a Type Theory that records usage information for each variable in a judgement, based on a previous system by McBride. The usage information is used to give a realizability semantics using a variant of Linear Combinatory Algebras, refining the usual realizability semantics of Type Theory by accurately tracking resource behaviour. We define the semantics in terms of Quantitative Categories with Families, a novel extension of Categories with Families for modelling resource sensitive type theories.},
	language = {en},
	booktitle = {Proceedings of the 33rd {Annual} {ACM}/{IEEE} {Symposium} on {Logic} in {Computer} {Science}},
	publisher = {ACM},
	author = {Atkey, Robert},
	month = jul,
	year = {2018},
	pages = {56--65},
	file = {Atkey - 2018 - Syntax and Semantics of Quantitative Type Theory.pdf:C\:\\Users\\mhuisi\\Zotero\\storage\\34P2XZ4I\\Atkey - 2018 - Syntax and Semantics of Quantitative Type Theory.pdf:application/pdf},
}

@mastersthesis{svoboda_additive_2021,
	title = {Additive {Pairs} in {Quantitative} {Type} {Theory}},
	url = {https://dspace.cuni.cz/bitstream/handle/20.500.11956/127263/120390849.pdf},
	abstract = {Both dependent types and linear types have their desirable properties. Department types can express functional dependencies of inputs and outputs, while linear types offer control over the use of computational resources. Combining these two systems have been difficult because of their different interpretations of context presence of variables. Quantitative Type Theory (QTT) combines dependent types and linear types by using a semiring to track the kind of use of every resource. We extend QTT with the additive pair and additive unit types, express the complete QTT rules in bidirectional form, and then present our interpreter of a simple language based on QTT.},
	language = {en},
	school = {Charles University},
	author = {Svoboda, Tomáš},
	year = {2021},
	file = {Svoboda - Additive Pairs in Quantitative Type Theory.pdf:C\:\\Users\\mhuisi\\Zotero\\storage\\4ARUG9H3\\Svoboda - Additive Pairs in Quantitative Type Theory.pdf:application/pdf},
}

@article{abel_syntax_nodate,
	title = {On the {Syntax} and {Semantics} of {Quantitative} {Typing} {Talk}},
	language = {en},
	author = {Abel, Andreas},
	pages = {15},
	file = {Abel - On the Syntax and Semantics of Quantitative Typing.pdf:C\:\\Users\\mhuisi\\Zotero\\storage\\BLA5Q486\\Abel - On the Syntax and Semantics of Quantitative Typing.pdf:application/pdf},
}

@article{choudhury_graded_2021,
	title = {A {Graded} {Dependent} {Type} {System} with a {Usage}-{Aware} {Semantics} (extended version)},
	abstract = {Graded Type Theory provides a mechanism to track and reason about resource usage in type systems. In this paper, we develop GraD, a novel version of such a graded dependent type system that includes functions, tensor products, additive sums, and a unit type. Since standard operational semantics is resource-agnostic, we develop a heap-based operational semantics and prove a soundness theorem that shows correct accounting of resource usage. Several useful properties, including the standard type soundness theorem, non-interference of irrelevant resources in computation and single pointer property for linear resources, can be derived from this theorem. We hope that our work will provide a base for integrating linearity, irrelevance and dependent types in practical programming languages like Haskell.},
	journal = {arXiv:2011.04070 [cs]},
	author = {Choudhury, Pritam and Eades III, Harley and Eisenberg, Richard A. and Weirich, Stephanie C.},
	month = jan,
	year = {2021},
	keywords = {Computer Science - Programming Languages, Computer Science - Logic in Computer Science},
	file = {arXiv Fulltext PDF:C\:\\Users\\mhuisi\\Zotero\\storage\\TGRSYICZ\\Choudhury et al. - 2021 - A graded dependent type system with a usage-aware .pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\mhuisi\\Zotero\\storage\\UY5X9H55\\2011.html:text/html},
}

@article{choudhury_dependent_2022,
	title = {A {Dependent} {Dependency} {Calculus} ({Extended} {Version})},
	url = {http://arxiv.org/abs/2201.11040},
	abstract = {Over twenty years ago, Abadi et al. established the Dependency Core Calculus (DCC) as a general purpose framework for analyzing dependency in typed programming languages. Since then, dependency analysis has shown many practical benefits to language design: its results can help users and compilers enforce security constraints, eliminate dead code, among other applications. In this work, we present a Dependent Dependency Calculus (DDC), which extends this general idea to the setting of a dependently-typed language. We use this calculus to track both run-time and compile-time irrelevance, enabling faster type-checking and program execution.},
	urldate = {2022-04-30},
	journal = {arXiv:2201.11040 [cs]},
	author = {Choudhury, Pritam and Eades III, Harley and Weirich, Stephanie},
	month = feb,
	year = {2022},
	note = {arXiv: 2201.11040},
	keywords = {Computer Science - Programming Languages},
	file = {arXiv Fulltext PDF:C\:\\Users\\mhuisi\\Zotero\\storage\\5Z3SR7U5\\Choudhury et al. - 2022 - A Dependent Dependency Calculus (Extended Version).pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\mhuisi\\Zotero\\storage\\3FZBCYUQ\\2201.html:text/html},
}

@article{moon_graded_2021,
	title = {Graded {Modal} {Dependent} {Type} {Theory}},
	abstract = {Graded type theories are an emerging paradigm for augmenting the reasoning power of types with parameterizable, fine-grained analyses of program properties. There have been many such theories in recent years which equip a type theory with quantitative dataflow tracking, usually via a semiring-like structure which provides analysis on variables (often called `quantitative' or `coeffect' theories). We present Graded Modal Dependent Type Theory (GrTT for short), which equips a dependent type theory with a general, parameterizable analysis of the flow of data, both in and between computational terms and types. In this theory, it is possible to study, restrict, and reason about data use in programs and types, enabling, for example, parametric quantifiers and linearity to be captured in a dependent setting. We propose GrTT, study its metatheory, and explore various case studies of its use in reasoning about programs and studying other type theories. We have implemented the theory and highlight the interesting details, including showing an application of grading to optimising the type checking procedure itself.},
	journal = {arXiv:2010.13163 [cs]},
	author = {Moon, Benjamin and Eades III, Harley and Orchard, Dominic},
	month = feb,
	year = {2021},
	keywords = {Computer Science - Logic in Computer Science},
	file = {arXiv Fulltext PDF:C\:\\Users\\mhuisi\\Zotero\\storage\\XNVMUL6M\\Moon et al. - 2021 - Graded Modal Dependent Type Theory.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\mhuisi\\Zotero\\storage\\37SD6NGD\\2010.html:text/html},
}

@article{abel_resourceful_nodate,
	title = {Resourceful {Dependent} {Types}},
	language = {en},
	author = {Abel, Andreas},
	pages = {2},
	file = {Abel - Resourceful Dependent Types.pdf:C\:\\Users\\mhuisi\\Zotero\\storage\\95PUBKJ3\\Abel - Resourceful Dependent Types.pdf:application/pdf},
}

@misc{grenrus_dependent_2020,
	type = {Blog},
	title = {Dependent {Linear} types in {QTT}},
	url = {https://oleg.fi/gists/posts/2020-12-18-dependent-linear.html},
	urldate = {2022-04-30},
	journal = {Oleg's gists},
	author = {Grenrus, Oleg},
	month = dec,
	year = {2020},
	file = {Oleg's gists - Dependent Linear types in QTT:C\:\\Users\\mhuisi\\Zotero\\storage\\WW92NAAI\\2020-12-18-dependent-linear.html:text/html},
}

@incollection{sergey_linearity_2022,
	address = {Cham},
	title = {Linearity and {Uniqueness}: {An} {Entente} {Cordiale}},
	volume = {13240},
	isbn = {978-3-030-99335-1 978-3-030-99336-8},
	shorttitle = {Linearity and {Uniqueness}},
	abstract = {Substructural type systems are growing in popularity because they allow for a resourceful interpretation of data which can be used to rule out various software bugs. Indeed, substructurality is ﬁnally taking hold in modern programming; Haskell now has linear types roughly based on Girard’s linear logic but integrated via graded function arrows, Clean has uniqueness types designed to ensure that values have at most a single reference to them, and Rust has an intricate ownership system for guaranteeing memory safety. But despite this broad range of resourceful type systems, there is comparatively little understanding of their relative strengths and weaknesses or whether their underlying frameworks can be uniﬁed. There is often confusion about whether linearity and uniqueness are essentially the same, or are instead ‘dual’ to one another, or somewhere in between. This paper formalises the relationship between these two well-studied but rarely contrasted ideas, building on two distinct bodies of literature, showing that it is possible and advantageous to have both linear and unique types in the same type system. We study the guarantees of the resulting system and provide a practical implementation in the graded modal setting of the Granule language, adding a third kind of modality alongside coeﬀect and eﬀect modalities. We then demonstrate via a benchmark that our implementation beneﬁts from expected eﬃciency gains enabled by adding uniqueness to a language that already has a linear basis.},
	language = {en},
	booktitle = {Programming {Languages} and {Systems}},
	publisher = {Springer International Publishing},
	author = {Marshall, Daniel and Vollmer, Michael and Orchard, Dominic},
	editor = {Sergey, Ilya},
	year = {2022},
	doi = {10.1007/978-3-030-99336-8_13},
	note = {Series Title: Lecture Notes in Computer Science},
	pages = {346--375},
	file = {Marshall et al. - 2022 - Linearity and Uniqueness An Entente Cordiale.pdf:C\:\\Users\\mhuisi\\Zotero\\storage\\8M5S63T9\\Marshall et al. - 2022 - Linearity and Uniqueness An Entente Cordiale.pdf:application/pdf},
}

@article{abel_unified_2020,
	title = {A unified view of modalities in type systems},
	volume = {4},
	issn = {2475-1421},
	url = {https://dl.acm.org/doi/10.1145/3408972},
	doi = {10.1145/3408972},
	abstract = {We propose to unify the treatment of a broad range of modalities in typed lambda calculi. We do so by defining a generic structure of modalities, and show that this structure arises naturally from the structure of intuitionistic logic, and as such finds instances in a wide range of type systems previously described in literature. Despite this generality, this structure has a rich metatheory, which we expose.},
	language = {en},
	number = {ICFP},
	urldate = {2022-05-02},
	journal = {Proceedings of the ACM on Programming Languages},
	author = {Abel, Andreas and Bernardy, Jean-Philippe},
	month = aug,
	year = {2020},
	pages = {1--28},
	file = {Abel and Bernardy - 2020 - A unified view of modalities in type systems.pdf:C\:\\Users\\mhuisi\\Zotero\\storage\\MYJC6A8L\\Abel and Bernardy - 2020 - A unified view of modalities in type systems.pdf:application/pdf},
}

@misc{vries_uniqueness_nodate,
	title = {Uniqueness {Typing} {Simplified}},
	abstract = {Abstract. We present a uniqueness type system that is simpler than both Clean’s uniqueness system and a system we proposed previously. The new type system is straightforward to implement and add to existing compilers, and can easily be extended with advanced features such as higher rank types and impredicativity. We describe our implementation in Morrow, an experimental functional language with both these features. Finally, we prove soundness of the core type system with respect to the call-by-need lambda calculus. 1 Introduction to Uniqueness Typing An important property of pure functional programming languages is referential transparency: the same expression used twice must have the same value twice. This makes equational reasoning possible and aids program analysis, but most languages do not have this property. For example, in the following C fragment,},
	author = {Vries, Edsko De and Plasmeijer, Rinus and Abrahamson, David M.},
	file = {Citeseer - Full Text PDF:C\:\\Users\\mhuisi\\Zotero\\storage\\KBYG3G28\\Vries et al. - Uniqueness Typing Simplified.pdf:application/pdf;Citeseer - Snapshot:C\:\\Users\\mhuisi\\Zotero\\storage\\WU4PIT3S\\download.html:text/html},
}

@incollection{achten_modelling_2013,
	address = {Berlin, Heidelberg},
	title = {Modelling {Unique} and {Affine} {Typing} {Using} {Polymorphism}},
	volume = {8106},
	isbn = {978-3-642-40354-5 978-3-642-40355-2},
	url = {http://link.springer.com/10.1007/978-3-642-40355-2_13},
	abstract = {Uniqueness typing and aﬃne (or linear) typing are dual type systems. Uniqueness gives a guarantee that an term has not been shared, while aﬃnity imposes a restriction that a term may not be shared. We show that we can unify both concepts through polymorphism.},
	language = {en},
	urldate = {2022-09-02},
	booktitle = {The {Beauty} of {Functional} {Code}},
	publisher = {Springer Berlin Heidelberg},
	author = {de Vries, Edsko},
	editor = {Achten, Peter and Koopman, Pieter},
	year = {2013},
	doi = {10.1007/978-3-642-40355-2_13},
	note = {Series Title: Lecture Notes in Computer Science},
	pages = {181--192},
	file = {de Vries - 2013 - Modelling Unique and Affine Typing Using Polymorph.pdf:C\:\\Users\\mhuisi\\Zotero\\storage\\MTNT4KQ6\\de Vries - 2013 - Modelling Unique and Affine Typing Using Polymorph.pdf:application/pdf},
}

@misc{ho_aeneas_2022,
	title = {Aeneas: {Rust} {Verification} by {Functional} {Translation}},
	shorttitle = {Aeneas},
	url = {http://arxiv.org/abs/2206.07185},
	abstract = {We present Aeneas, a new verification toolchain for Rust programs based on a lightweight functional translation. We leverage Rust's rich region-based type system to eliminate memory reasoning for many Rust programs, as long as they do not rely on interior mutability or unsafe code. Doing so, we relieve the proof engineer of the burden of memory-based reasoning, allowing them to instead focus on functional properties of their code. Our first contribution is a new approach to borrows and controlled aliasing. We propose a pure, functional semantics for LLBC, a Low-Level Borrow Calculus that captures a large subset of Rust programs. Our semantics is value-based, meaning there is no notion of memory, addresses or pointer arithmetic. Our semantics is also ownership-centric, meaning that we enforce soundness of borrows via a semantic criterion based on loans rather than through a syntactic type-based lifetime discipline. We claim that our semantics captures the essence of the borrow mechanism rather than its current implementation in the Rust compiler. Our second contribution is a translation from LLBC to a pure lambda-calculus. This allows the user to reason about the original Rust program through the theorem prover of their choice. To deal with the well-known technical difficulty of terminating a borrow, we rely on a novel approach, in which we approximate the borrow graph in the presence of function calls. This in turn allows us to perform the translation using a new technical device called backward functions. We implement our toolchain in a mixture of Rust and OCaml. Our evaluation shows significant gains of verification productivity for the programmer. Rust goes to great lengths to enforce static control of aliasing; the proof engineer should not waste any time on memory reasoning when so much already comes "for free"!},
	urldate = {2022-08-23},
	publisher = {arXiv},
	author = {Ho, Son and Protzenko, Jonathan},
	month = jun,
	year = {2022},
	note = {arXiv:2206.07185 [cs]},
	keywords = {Computer Science - Programming Languages},
	file = {arXiv Fulltext PDF:C\:\\Users\\mhuisi\\Zotero\\storage\\8D2R8FRH\\Ho and Protzenko - 2022 - Aeneas Rust Verification by Functional Translatio.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\mhuisi\\Zotero\\storage\\CI76EEL8\\2206.html:text/html},
}

@article{li_linear_2022,
	title = {Linear {Types} for {Large}-{Scale} {Systems} {Verification}},
	volume = {6},
	doi = {10.1145/3527313},
	abstract = {Reasoning about memory aliasing and mutation in software verification is a hard problem. This is especially true for systems using SMT-based automated theorem provers. Memory reasoning in SMT verification typically requires a nontrivial amount of manual effort to specify heap invariants, as well as extensive alias reasoning from the SMT solver. In this paper, we present a hybrid approach that combines linear types with SMT-based verification for memory reasoning. We integrate linear types into Dafny, a verification language with an SMT backend, and show that the two approaches complement each other. By separating memory reasoning from verification conditions, linear types reduce the SMT solving time. At the same time, the expressiveness of SMT queries extends the flexibility of the linear type system. In particular, it allows our linear type system to easily and correctly mix linear and nonlinear data in novel ways, encapsulating linear data inside nonlinear data and vice-versa. We formalize the core of our extensions, prove soundness, and provide algorithms for linear type checking. We evaluate our approach by converting the implementation of a verified storage system (about 24K lines of code and proof) written in Dafny, to use our extended Dafny. The resulting system uses linear types for 91\% of the code and SMT-based heap reasoning for the remaining 9\%. We show that the converted system has 28\% fewer lines of proofs and 30\% shorter verification time overall. We discuss the development overhead in the original system due to SMT-based heap reasoning and highlight the improved developer experience when using linear types.},
	number = {OOPSLA1},
	journal = {Proceedings of the ACM on Programming Languages},
	author = {Li, Jialin and Lattuada, Andrea and Zhou, Yi and Cameron, Jonathan and Howell, Jon and Parno, Bryan and Hawblitzel, Chris},
	month = apr,
	year = {2022},
	keywords = {linear types, systems verification},
	pages = {69:1--69:28},
	file = {Full Text PDF:C\:\\Users\\mhuisi\\Zotero\\storage\\BWAPPUWI\\Li et al. - 2022 - Linear types for large-scale systems verification.pdf:application/pdf},
}

@article{oconnor_cogent_2021,
	title = {Cogent: uniqueness types and certifying compilation},
	volume = {31},
	issn = {0956-7968, 1469-7653},
	shorttitle = {Cogent},
	doi = {10.1017/S095679682100023X},
	abstract = {Abstract
            This paper presents a framework aimed at significantly reducing the cost of proving functional correctness for low-level operating systems components. The framework is designed around a new functional programming language, Cogent. A central aspect of the language is its uniqueness type system, which eliminates the need for a trusted runtime or garbage collector while still guaranteeing memory safety, a crucial property for safety and security. Moreover, it allows us to assign two semantics to the language: The first semantics is imperative, suitable for efficient C code generation, and the second is purely functional, providing a user-friendly interface for equational reasoning and verification of higher-level correctness properties. The refinement theorem connecting the two semantics allows the compiler to produce a proof via translation validation certifying the correctness of the generated C code with respect to the semantics of the Cogent source program. We have demonstrated the effectiveness of our framework for implementation and for verification through two file system implementations.},
	language = {en},
	journal = {Journal of Functional Programming},
	author = {O’Connor, Liam and Chen, Zilin and Rizkallah, Christine and Jackson, Vincent and Amani, Sidney and Klein, Gerwin and Murray, Toby and Sewell, Thomas and Keller, Gabriele},
	year = {2021},
	pages = {e25},
	file = {O’Connor et al. - 2021 - Cogent uniqueness types and certifying compilatio.pdf:C\:\\Users\\mhuisi\\Zotero\\storage\\FWNDFPPB\\O’Connor et al. - 2021 - Cogent uniqueness types and certifying compilatio.pdf:application/pdf},
}

@incollection{aspinall_another_2002,
	address = {Berlin, Heidelberg},
	title = {Another {Type} {System} for {In}-{Place} {Update}},
	volume = {2305},
	isbn = {978-3-540-43363-7 978-3-540-45927-9},
	abstract = {Linear typing schemes guarantee single-threadedness and so the soundness of in-place update with respect to a functional semantics. But linear schemes are restrictive in practice, and more restrictive than necessary to guarantee soundness of in-place update. This has prompted research into static analysis and more sophisticated typing disciplines, to determine when in-place update may be safely used, or to combine linear and non-linear schemes. Here we contribute to this line of research by deﬁning a new typing scheme which better approximates the semantic property of soundness of in-place update for a functional semantics. Our typing scheme includes two kinds of products (⊗ and ×), which allows data structures with or without sharing to be deﬁned. We begin from the observation that some data is used only in a “read-only” context after which it may be safely re-used before being destroyed. Formalizing the inplace update interpretation and giving a machine model semantics allows us to reﬁne this observation. We deﬁne three usage aspects apparent from the semantics, which are used to annotate function argument types. The aspects are (1) used destructively, (2) used read-only but shared with result, and (3) used read-only and not shared.},
	language = {en},
	booktitle = {Programming {Languages} and {Systems}},
	publisher = {Springer},
	author = {Aspinall, David and Hofmann, Martin},
	year = {2002},
	doi = {10.1007/3-540-45927-8_4},
	note = {Series Title: Lecture Notes in Computer Science},
	pages = {36--52},
	file = {Aspinall and Hofmann - 2002 - Another Type System for In-Place Update.pdf:C\:\\Users\\mhuisi\\Zotero\\storage\\BHQ36ZCT\\Aspinall and Hofmann - 2002 - Another Type System for In-Place Update.pdf:application/pdf},
}

@inproceedings{kobayashi_quasi-linear_1999,
	address = {San Antonio, Texas, United States},
	title = {Quasi-{Linear} {Types}},
	isbn = {978-1-58113-095-9},
	doi = {10.1145/292540.292546},
	abstract = {Linear types (types of values that can be used just once) have been drawing a great deal of attention because they are useful for memory management, in-place update of data structures, etc.: an obvious advantage is that a value of a linear type can be immediately deallocated after being used. However, the linear types have not been applied so widely in practice, probably because linear values (values of linear types) in the traditional sense do not so often appear in actual programs. In order to increase the applicability of linear types, we relax the condition of linearity by extending the types with information on an evaluation order and simple dataflow information. The extended type system, called a quasi-linear type system, is formalized and its correctness is proved. We have implemented a prototype type inference system for the core-ML that can automatically find out which value is linear in the relaxed sense. Promising results were obtained from preliminary experiments with the prototype system.},
	language = {en},
	booktitle = {Proceedings of the 26th {ACM} {SIGPLAN}-{SIGACT} symposium on {Principles} of programming languages  - {POPL} '99},
	publisher = {ACM Press},
	author = {Kobayashi, Naoki},
	year = {1999},
	pages = {29--42},
	file = {Kobayashi - 1999 - Quasi-linear types.pdf:C\:\\Users\\mhuisi\\Zotero\\storage\\IVP5EWFI\\Kobayashi - 1999 - Quasi-linear types.pdf:application/pdf},
}

@misc{noauthor_vries_nodate,
	title = {de {Vries} {Thesis}},
	file = {thesis.pdf:C\:\\Users\\mhuisi\\Zotero\\storage\\TSWCUECB\\thesis.pdf:application/pdf},
}

@misc{noauthor_oconnor_nodate,
	title = {{OConnor} {Thesis}},
	file = {liam-oconnor-phd-thesis.pdf:C\:\\Users\\mhuisi\\Zotero\\storage\\G6CWSXKX\\liam-oconnor-phd-thesis.pdf:application/pdf},
}

@misc{noauthor_weirich_nodate,
	title = {Weirich {QTT} {Talk}},
	file = {1584070624-w28-qtt-zion.pdf:C\:\\Users\\mhuisi\\Zotero\\storage\\ZEFBQHHY\\1584070624-w28-qtt-zion.pdf:application/pdf},
}

@misc{noauthor_brady_nodate,
	title = {Brady {Student} {Thesis}},
	file = {Brady Student Thesis.pdf:C\:\\Users\\mhuisi\\Zotero\\storage\\WP9QREWN\\Brady Student Thesis.pdf:application/pdf},
}

@incollection{odersky_observers_1992,
	address = {Berlin, Heidelberg},
	title = {Observers for {Linear} {Types}},
	volume = {582},
	isbn = {978-3-540-55253-6 978-3-540-46803-5},
	abstract = {Linear types provide the framework for a safe embedding of mutable state in functional languages by enforcing the principle that variables of linear type must bc used exactly once. A potential disadvantage of this approach is that it places read accesses to such variables under the same restriction as write accesses, and thus prevents reads to proceed in parallel. We present here an extcnsion of linear types which augments the usual distinction between linear and non-linear by a third state, observers of linear variables. Since, unlike linear variables, observers can be duplicated, multiple concurrent reads are made possible. On the other hand, observers must be short-lived enough to never overlap with mutations. The resulting type system is in many aspects similar to the one of ML: It is polymorphic, has principal types, and admits a type reconstruction algorithm.},
	language = {en},
	booktitle = {{ESOP} '92},
	publisher = {Springer Berlin Heidelberg},
	author = {Odersky, Martin},
	year = {1992},
	doi = {10.1007/3-540-55253-7_23},
	note = {Series Title: Lecture Notes in Computer Science},
	pages = {390--407},
	file = {Odersky - 1992 - Observers for linear types.pdf:C\:\\Users\\mhuisi\\Zotero\\storage\\5UQTUCJ3\\Odersky - 1992 - Observers for linear types.pdf:application/pdf},
}

@article{pottier_wandering_nodate,
	title = {Wandering through linear types, capabilities, and regions},
	language = {en},
	author = {Pottier, François},
	pages = {114},
	file = {Pottier - Wandering through linear types, capabilities, and .pdf:C\:\\Users\\mhuisi\\Zotero\\storage\\UG6R3Z4Y\\Pottier - Wandering through linear types, capabilities, and .pdf:application/pdf},
}

@article{spiwack_linearly_2022,
	title = {Linearly {Qualified} {Types}: {Generic} {Inference} for {Capabilities} and {Uniqueness}},
	volume = {6},
	issn = {2475-1421},
	shorttitle = {Linearly qualified types},
	doi = {10.1145/3547626},
	abstract = {ARNAUD SPIWACK, Tweag, France CSONGOR KISS, Imperial College London, United Kingdom JEAN-PHILIPPE BERNARDY, University of Gothenburg, Sweden NICOLAS WU, Imperial College London, United Kingdom RICHARD A. EISENBERG, Tweag, France A linear parameter must be consumed exactly once in the body of its function. When declaring resources such as file handles and manually managed memory as linear arguments, a linear type system can verify that these resources are used safely. However, writing code with explicit linear arguments requires bureaucracy. This paper presents linear constraints, a front-end feature for linear typing that decreases the bureaucracy of working with linear types. Linear constraints are implicit linear arguments that are filled in automatically by the compiler. We present linear constraints as a qualified type system, together with an inference algorithm which extends ghc’s existing constraint solver algorithm. Soundness of linear constraints is ensured by the fact that they desugar into Linear Haskell. CCS Concepts: • Software and its engineering → Language features; Functional languages; Formal language definitions.},
	language = {en},
	number = {ICFP},
	journal = {Proceedings of the ACM on Programming Languages},
	author = {Spiwack, Arnaud and Kiss, Csongor and Bernardy, Jean-Philippe and Wu, Nicolas and Eisenberg, Richard A.},
	month = aug,
	year = {2022},
	pages = {137--164},
	file = {Spiwack et al. - 2022 - Linearly qualified types generic inference for ca.pdf:C\:\\Users\\mhuisi\\Zotero\\storage\\ZDK8D9VK\\Spiwack et al. - 2022 - Linearly qualified types generic inference for ca.pdf:application/pdf},
}

@article{scheper_escape_nodate,
	title = {Escape {Analysis} for the {Glasgow} {Haskell} {Compiler}},
	language = {de},
	author = {Scheper, Sebastian},
	pages = {56},
	file = {Scheper - Escape Analysis for the Glasgow Haskell Compiler.pdf:C\:\\Users\\mhuisi\\Zotero\\storage\\MDMM5PRB\\Scheper - Escape Analysis for the Glasgow Haskell Compiler.pdf:application/pdf},
}

@inproceedings{smetsers_guaranteeing_1994,
	address = {Berlin, Heidelberg},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Guaranteeing {Safe} {Destructive} {Updates} through a {Type} {System} with {Uniqueness} {Information} for {Graphs}},
	isbn = {978-3-540-48333-5},
	doi = {10.1007/3-540-57787-4_23},
	abstract = {In this paper we present a type system for graph rewrite systems: uniqueness typing. It employs usage information to deduce whether an object is ‘unique’ at a certain moment, i.e. is only locally accessible. In a type of a function it can be specified that the function requires a unique argument object. The correctness of type assignment guarantees that no external access on the original object will take place in the future. The presented type system is proven to be correct. We illustrate the power of the system by defining an elegant quicksort algorithm that performs the sorting in situ on the data structure.},
	language = {en},
	booktitle = {Graph {Transformations} in {Computer} {Science}},
	publisher = {Springer},
	author = {Smetsers, Sjaak and Barendsen, Erik and van Eekelen, Marko and Plasmeijer, Rinus},
	year = {1994},
	keywords = {Functional Language, Functional Program, Reduction Rule, Type System, Uniqueness Type},
	pages = {358--379},
	file = {Full Text PDF:C\:\\Users\\mhuisi\\Zotero\\storage\\JS38ENV7\\Smetsers et al. - 1994 - Guaranteeing safe destructive updates through a ty.pdf:application/pdf},
}

@inproceedings{de_moura_lean_2021,
	address = {Cham},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {The {Lean} 4 {Theorem} {Prover} and {Programming} {Language}},
	isbn = {978-3-030-79876-5},
	doi = {10.1007/978-3-030-79876-5_37},
	abstract = {Lean 4 is a reimplementation of the Lean interactive theorem prover (ITP) in Lean itself. It addresses many shortcomings of the previous versions and contains many new features. Lean 4 is fully extensible: users can modify and extend the parser, elaborator, tactics, decision procedures, pretty printer, and code generator. The new system has a hygienic macro system custom-built for ITPs. It contains a new typeclass resolution procedure based on tabled resolution, addressing significant performance problems reported by the growing user base. Lean 4 is also an efficient functional programming language based on a novel programming paradigm called functional but in-place. Efficient code generation is crucial for Lean users because many write custom proof automation procedures in Lean itself.},
	language = {en},
	booktitle = {Automated {Deduction} – {CADE} 28},
	publisher = {Springer International Publishing},
	author = {de Moura, Leonardo and Ullrich, Sebastian},
	year = {2021},
	keywords = {Lean},
	pages = {625--635},
	file = {Full Text PDF:C\:\\Users\\mhuisi\\Zotero\\storage\\RYXPDRJ3\\Moura and Ullrich - 2021 - The Lean 4 Theorem Prover and Programming Language.pdf:application/pdf},
}

@article{sharir_strong-connectivity_1981,
	title = {A strong-connectivity algorithm and its applications in data flow analysis},
	volume = {7},
	issn = {0898-1221},
	doi = {10.1016/0898-1221(81)90008-0},
	abstract = {We present a new linear algorithm for constructing all strongly connected components of a directed graph, and show how to apply it in iterative solution of data-flow analysis problems, to obtain a simple algorithm which improves the Hecht-Ullman algorithm.},
	language = {en},
	number = {1},
	journal = {Computers \& Mathematics with Applications},
	author = {Sharir, M.},
	month = jan,
	year = {1981},
	pages = {67--72},
	file = {ScienceDirect Full Text PDF:C\:\\Users\\mhuisi\\Zotero\\storage\\RYIJWZHT\\Sharir - 1981 - A strong-connectivity algorithm and its applicatio.pdf:application/pdf;ScienceDirect Snapshot:C\:\\Users\\mhuisi\\Zotero\\storage\\9W6GC2AA\\0898122181900080.html:text/html},
}

@article{tarjan_depth-first_1972,
	title = {Depth-{First} {Search} and {Linear} {Graph} {Algorithms}},
	volume = {1},
	issn = {0097-5397},
	doi = {10.1137/0201010},
	abstract = {An algorithm is presented which finds all the elementary circuits of a directed graph in time bounded by \$O((n + e)(c + 1))\$ and space bounded by \$O(n + e)\$, where there are n vertices, e edges and c elementary circuits in the graph. The algorithm resembles algorithms by Tiernan and Tarjan, but is faster because it considers each edge at most twice between any one circuit and the next in the output sequence.},
	number = {2},
	journal = {SIAM Journal on Computing},
	author = {Tarjan, Robert},
	month = jun,
	year = {1972},
	note = {Publisher: Society for Industrial and Applied Mathematics},
	pages = {146--160},
	file = {Full Text PDF:C\:\\Users\\mhuisi\\Zotero\\storage\\SNHF6VLC\\Tarjan - 1972 - Depth-First Search and Linear Graph Algorithms.pdf:application/pdf},
}

@book{avigad_theorem_2022,
	title = {Theorem {Proving} in {Lean} 4},
	url = {https://leanprover.github.io/theorem_proving_in_lean4},
	urldate = {2023-02-19},
	author = {Avigad, Jeremy and de Moura, Leonardo and Kong, Soonho and Ullrich, Sebastian},
	year = {2022},
}

@book{christiansen_functional_2023,
	title = {Functional {Programming} in {Lean}},
	url = {https://leanprover.github.io/functional_programming_in_lean/},
	urldate = {2023-02-19},
	author = {Christiansen, David Thrane},
	year = {2023},
}

@mastersthesis{carneiro_type_2019,
	address = {Pittsburgh, Pennsylvania},
	title = {The {Type} {Theory} of {Lean}},
	url = {https://github.com/digama0/lean-type-theory/releases/download/v1.0/main.pdf},
	abstract = {This thesis is a presentation of dependent type theory with inductive types, a hierarchy of universes, with an impredicative universe of propositions, proof irrelevance, and subsingleton elimination, along with axioms for propositional extensionality, quotient types, and the axiom of choice. This
theory is notable for being the axiomatic framework of the Lean theorem prover. The axiom system is given here in complete detail, including “optional” features of the type system such as let binders and definitions. We provide a reduction of the theory to a finitely axiomatized fragment utilizing a fixed set of inductive types (the W-type plus a few others), to ease the study of this framework.
The metatheory of this theory (which we will call Lean) is studied. In particular, we prove unique typing of the definitional equality, and use this to construct the expected set-theoretic model, from
which we derive consistency of Lean relative to ZFC + \{there are n inaccessible cardinals {\textbar} n {\textless} ω\} (a relatively weak large cardinal assumption). As Lean supports models of ZFC with n inaccessible
cardinals, this is optimal.
We also show a number of negative results, where the theory is less nice than we would like. In particular, type checking is undecidable, and the type checking as implemented by the Lean theorem prover is a decidable non-transitive underapproximation of the typing judgment. Nontransitivity also leads to lack of subject reduction, and the reduction relation does not satisfy the
Church-Rosser property, so reduction to a normal form does not produce a decision procedure for definitional equality. However, a modified reduction relation allows us to restore the Church-Rosser
property at the expense of guaranteed termination, so that unique typing is shown to hold.},
	language = {English},
	urldate = {2023-02-19},
	school = {Carnegie Mellon University},
	author = {Carneiro, Mario},
	month = apr,
	year = {2019},
}

@misc{ullrich_beyond_2022,
	title = {Beyond {Notations}: {Hygienic} {Macro} {Expansion} for {Theorem} {Proving} {Languages}},
	shorttitle = {Beyond {Notations}},
	doi = {10.48550/arXiv.2001.10490},
	abstract = {In interactive theorem provers (ITPs), extensible syntax is not only crucial to lower the cognitive burden of manipulating complex mathematical objects, but plays a critical role in developing reusable abstractions in libraries. Most ITPs support such extensions in the form of restrictive "syntax sugar" substitutions and other ad hoc mechanisms, which are too rudimentary to support many desirable abstractions. As a result, libraries are littered with unnecessary redundancy. Tactic languages in these systems are plagued by a seemingly unrelated issue: accidental name capture, which often produces unexpected and counterintuitive behavior. We take ideas from the Scheme family of programming languages and solve these two problems simultaneously by proposing a novel hygienic macro system custom-built for ITPs. We further describe how our approach can be extended to cover type-directed macro expansion resulting in a single, uniform system offering multiple abstraction levels that range from supporting simplest syntax sugars to elaboration of formerly baked-in syntax. We have implemented our new macro system and integrated it into the new version of the Lean theorem prover, Lean 4. Despite its expressivity, the macro system is simple enough that it can easily be integrated into other systems.},
	publisher = {arXiv},
	author = {Ullrich, Sebastian and de Moura, Leonardo},
	month = apr,
	year = {2022},
	note = {arXiv:2001.10490 [cs]},
	keywords = {Computer Science - Programming Languages},
	file = {arXiv Fulltext PDF:C\:\\Users\\mhuisi\\Zotero\\storage\\2P2ZI8LW\\Ullrich and de Moura - 2022 - Beyond Notations Hygienic Macro Expansion for The.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\mhuisi\\Zotero\\storage\\WJ563W7K\\2001.html:text/html},
}

@article{jones_practical_2007,
	title = {Practical type inference for arbitrary-rank types},
	volume = {17},
	issn = {0956-7968, 1469-7653},
	doi = {10.1017/S0956796806006034},
	abstract = {Haskell’s popularity has driven the need for ever more expressive type system features, most of which threaten the decidability and practicality of Damas-Milner type inference. One such feature is the ability to write functions with higher-rank types—that is, functions that take polymorphic functions as their arguments.},
	language = {en},
	number = {1},
	journal = {Journal of Functional Programming},
	author = {Jones, Simon Peyton and Vytiniotis, Dimitrios and Weirich, Stephanie and Shields, Mark},
	month = jan,
	year = {2007},
	pages = {1--82},
	file = {Jones et al. - 2007 - Practical type inference for arbitrary-rank types.pdf:C\:\\Users\\mhuisi\\Zotero\\storage\\2VGG6DY3\\Jones et al. - 2007 - Practical type inference for arbitrary-rank types.pdf:application/pdf},
}

@article{matsuda_sparcl_2020,
	title = {Sparcl: {A} {Language} for {Partially}-{Invertible} {Computation}},
	volume = {4},
	issn = {2475-1421},
	shorttitle = {Sparcl},
	doi = {10.1145/3409000},
	abstract = {KAZUTAKA MATSUDA, Tohoku University, Japan MENG WANG, University of Bristol, United Kingdom Invertibility is a fundamental concept in computer science, with various manifestations in software development (serializer/deserializer, parser/printer, redo/undo, compressor/decompressor, and so on). Full invertibility necessarily requires bijectivity, but the direct approach of composing bijective functions to develop invertible programs is too restrictive to be useful. In this paper, we take a different approach by focusing on partiallyinvertible functionsÐfunctions that become invertible if some of their arguments are fixed. The simplest example of such is addition, which becomes invertible when fixing one of the operands. More involved examples include entropy-based compression methods (e.g., Huffman coding), which carry the occurrence frequency of input symbols (in certain formats such as Huffman tree), and fixing this frequency information makes the compression methods invertible. We develop a language Sparcl for programming such functions in a natural way, where partial-invertibility is the norm and bijectivity is a special case, hence gaining significant expressiveness without compromising correctness. The challenge in designing such a language is to allow ordinary programming (the łpartiallyž part) to interact with the invertible part freely, and yet guarantee invertibility by construction. The language Sparcl is linear-typed, and has a type constructor to distinguish data that are subject to invertible computation and those that are not. We present the syntax, type system, and semantics of the language, and prove that Sparcl correctly guarantees invertibility for its programs. We demonstrate the expressiveness of Sparcl with examples including tree rebuilding from preorder and inorder traversals and Huffman coding. CCS Concepts: • Software and its engineering → Functional languages; Domain specific languages.},
	language = {en},
	number = {ICFP},
	journal = {Proceedings of the ACM on Programming Languages},
	author = {Matsuda, Kazutaka and Wang, Meng},
	month = aug,
	year = {2020},
	pages = {1--31},
	file = {Matsuda and Wang - 2020 - Sparcl a language for partially-invertible comput.pdf:C\:\\Users\\mhuisi\\Zotero\\storage\\HUGIGG4R\\Matsuda and Wang - 2020 - Sparcl a language for partially-invertible comput.pdf:application/pdf},
}

@article{barendsen_uniqueness_1996,
	title = {Uniqueness typing for functional languages with graph rewriting semantics},
	volume = {6},
	issn = {0960-1295, 1469-8072},
	doi = {10.1017/S0960129500070109},
	abstract = {We present two type systems for term graph rewriting: conventional typing and (polymorphic) uniqueness typing. The latter is introduced as a natural extension of simple algebraic and higher-order uniqueness typing. The systems are given in natural deduction style using an inductive syntax of graph denotations with familiar constructs such as let and case.The conventional system resembles traditional Curry-style typing systems in functional programming languages. Uniqueness typing extends this with reference count information. In both type systems, typing is preserved during evaluation, and types can be determined effectively. Moreover, with respect to a graph rewriting semantics, both type systems turn out to be sound.},
	language = {en},
	number = {6},
	journal = {Mathematical Structures in Computer Science},
	author = {Barendsen, Erik and Smetsers, Sjaak},
	month = dec,
	year = {1996},
	note = {Publisher: Cambridge University Press},
	pages = {579--612},
}

@phdthesis{de_vries_making_2009,
	type = {{PhD} thesis},
	title = {Making {Uniqueness} {Typing} {Less} {Unique}},
	url = {http://www.tara.tcd.ie/handle/2262/90081},
	abstract = {Computer science distinguishes between two major programming paradigms: imperative and
functional programming. Central to imperative programming is the notion of some form of
state (or memory) together with a list of instructions that inspect and modify that state. The
canonical example of this paradigm is the Turing machine. Functional programming on the
other hand is centred around a mathematical language with a notion of evaluation of expressions in this language. The notion of state- the core concept in imperative programming- is completely absent. The canonical example of the functional paradigm is the lambda calculus.},
	language = {en},
	urldate = {2023-02-20},
	school = {Trinity College (Dublin, Ireland). School of Computer Science \& Statistics},
	author = {de Vries, Edsko},
	year = {2009},
	file = {Full Text PDF:C\:\\Users\\mhuisi\\Zotero\\storage\\XB54KYCE\\Vries and Jelle - 2009 - Making uniqueness typing less unique.pdf:application/pdf},
}

@article{tov_practical_2011,
	title = {Practical {Affine} {Types}},
	volume = {46},
	issn = {0362-1340},
	doi = {10.1145/1925844.1926436},
	abstract = {Alms is a general-purpose programming language that supports practical affine types. To offer the expressiveness of Girard's linear logic while keeping the type system light and convenient, Alms uses expressive kinds that minimize notation while maximizing polymorphism between affine and unlimited types. A key feature of Alms is the ability to introduce abstract affine types via ML-style signature ascription. In Alms, an interface can impose stiffer resource usage restrictions than the principal usage restrictions of its implementation. This form of sealing allows the type system to naturally and directly express a variety of resource management protocols from special-purpose type systems. We present two pieces of evidence to demonstrate the validity of our design goals. First, we introduce a prototype implementation of Alms and discuss our experience programming in the language. Second, we establish the soundness of the core language. We also use the core model to prove a principal kinding theorem.},
	number = {1},
	journal = {ACM SIGPLAN Notices},
	author = {Tov, Jesse A. and Pucella, Riccardo},
	month = jan,
	year = {2011},
	keywords = {affine types, linear logic, modules, polymorphism, type systems},
	pages = {447--458},
	file = {Full Text PDF:C\:\\Users\\mhuisi\\Zotero\\storage\\JTQ6UBVM\\Tov and Pucella - 2011 - Practical affine types.pdf:application/pdf},
}

@article{chirimar_reference_1996,
	title = {Reference counting as a computational interpretation of linear logic},
	volume = {6},
	issn = {1469-7653, 0956-7968},
	doi = {10.1017/S0956796800001660},
	abstract = {We develop an operational model for a language based on linear logic. Our semantics is ‘low-level’ enough to express sharing and copying while still being ‘high-level’ enough to abstract away from details of memory layout, and thus can be used to test potential applications of linear logic for analysis of programs. In particular, we demonstrate a precise relationship between type correctness for the linear-logic-based language and the correctness of a reference-counting interpretation of the primitives, and formulate and prove a result describing the possible run-time reference counts of values of linear type.},
	language = {en},
	number = {2},
	journal = {Journal of Functional Programming},
	author = {Chirimar, Jawahar and Gunter, Carl A. and Riecke, Jon G.},
	month = mar,
	year = {1996},
	note = {Publisher: Cambridge University Press},
	pages = {195--244},
	file = {Full Text PDF:C\:\\Users\\mhuisi\\Zotero\\storage\\R9LWW87A\\Chirimar et al. - 1996 - Reference counting as a computational interpretati.pdf:application/pdf},
}

@article{bernardy_linear_2018,
	title = {Linear {Haskell}: {Practical} {Linearity} in a {Higher}-{Order} {Polymorphic} {Language}},
	volume = {2},
	issn = {2475-1421},
	shorttitle = {Linear {Haskell}},
	doi = {10.1145/3158093},
	abstract = {Linear type systems have a long and storied history, but not a clear path forward to integrate with existing languages such as OCaml or Haskell. In this paper, we study a linear type system designed with two crucial properties in mind: backwards-compatibility and code reuse across linear and non-linear users of a library. Only then can the benefits of linear types permeate conventional functional programming. Rather than bifurcate types into linear and non-linear counterparts, we instead attach linearity to function arrows. Linear functions can receive inputs from linearly-bound values, but can also operate over unrestricted, regular values. To demonstrate the efficacy of our linear type system - both how easy it can be integrated in an existing language implementation and how streamlined it makes it to write programs with linear types - we implemented our type system in GHC, the leading Haskell compiler, and demonstrate two kinds of applications of linear types: mutable data with pure interfaces; and enforcing protocols in I/O-performing functions.},
	number = {POPL},
	journal = {Proceedings of the ACM on Programming Languages},
	author = {Bernardy, Jean-Philippe and Boespflug, Mathieu and Newton, Ryan R. and Jones, Simon Peyton and Spiwack, Arnaud},
	month = jan,
	year = {2018},
	note = {arXiv:1710.09756 [cs]},
	keywords = {Computer Science - Programming Languages},
	pages = {1--29},
	file = {arXiv Fulltext PDF:C\:\\Users\\mhuisi\\Zotero\\storage\\QA5JX7CM\\Bernardy et al. - 2018 - Linear Haskell practical linearity in a higher-or.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\mhuisi\\Zotero\\storage\\URFJ6IE7\\1710.html:text/html},
}

@misc{weiss_oxide_2021,
	title = {Oxide: {The} {Essence} of {Rust}},
	shorttitle = {Oxide},
	doi = {10.48550/arXiv.1903.00982},
	abstract = {Rust claims to advance industrial programming by bridging the gap between low-level systems programming and high-level application programming. At the heart of the argument that this enables programmers to build more reliable and efficient software is the borrow checker - a novel approach to ownership that aims to balance type system expressivity with usability. And yet, to date there is no core type system that captures Rust's notion of ownership and borrowing, and hence no foundation for research on Rust to build upon. In this work, we set out to capture the essence of this model of ownership by developing a type systems account of Rust's borrow checker. We present Oxide, a formalized programming language close to source-level Rust (but with fully-annotated types). This presentation takes a new view of lifetimes as an approximation of the provenances of references, and our type system is able to automatically compute this information through a substructural typing judgment. We provide the first syntactic proof of type safety for borrow checking using progress and preservation. Oxide is a simpler formulation of borrow checking - including recent features such as non-lexical lifetimes - that we hope researchers will be able to use as the basis for work on Rust.},
	publisher = {arXiv},
	author = {Weiss, Aaron and Gierczak, Olek and Patterson, Daniel and Ahmed, Amal},
	month = oct,
	year = {2021},
	note = {arXiv:1903.00982 [cs]},
	keywords = {Computer Science - Programming Languages},
	file = {arXiv Fulltext PDF:C\:\\Users\\mhuisi\\Zotero\\storage\\J9YM5F29\\Weiss et al. - 2021 - Oxide The Essence of Rust.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\mhuisi\\Zotero\\storage\\7M5486E4\\1903.html:text/html},
}

@article{wadler_is_1991,
	title = {Is there a use for linear logic?},
	volume = {26},
	issn = {0362-1340},
	doi = {10.1145/115866.115894},
	number = {9},
	journal = {ACM SIGPLAN Notices},
	author = {Wadler, Philip},
	month = may,
	year = {1991},
	pages = {255--273},
	file = {Full Text PDF:C\:\\Users\\mhuisi\\Zotero\\storage\\YR3WGRJS\\Wadler - 1991 - Is there a use for linear logic.pdf:application/pdf},
}

@article{girard_linear_1987,
	title = {Linear logic},
	volume = {50},
	issn = {0304-3975},
	doi = {10.1016/0304-3975(87)90045-4},
	abstract = {The familiar connective of negation is broken into two operations: linear negation which is the purely negative part of negation and the modality “of course” which has the meaning of a reaffirmation. Following this basic discovery, a completely new approach to the whole area between constructive logics and programmation is initiated.},
	language = {en},
	number = {1},
	journal = {Theoretical Computer Science},
	author = {Girard, Jean-Yves},
	month = jan,
	year = {1987},
	pages = {1--101},
	file = {ScienceDirect Full Text PDF:C\:\\Users\\mhuisi\\Zotero\\storage\\3BTQ9XKF\\Girard - 1987 - Linear logic.pdf:application/pdf;ScienceDirect Snapshot:C\:\\Users\\mhuisi\\Zotero\\storage\\4L93B24T\\0304397587900454.html:text/html},
}

@inproceedings{ghica_bounded_2014,
	address = {Berlin, Heidelberg},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Bounded {Linear} {Types} in a {Resource} {Semiring}},
	isbn = {978-3-642-54833-8},
	doi = {10.1007/978-3-642-54833-8_18},
	abstract = {Bounded linear types have proved to be useful for automated resource analysis and control in functional programming languages. In this paper we introduce a bounded linear typing discipline on a general notion of resource which can be modeled in a semiring. For this type system we provide both a general type-inference procedure, parameterized by the decision procedure of the semiring equational theory, and a (coherent) categorical semantics. This could be a useful type-theoretic and denotational framework for resource-sensitive compilation, and it represents a generalization of several existing type systems. As a non-trivial instance, motivated by hardware compilation, we present a complex new application to calculating and controlling timing of execution in a (recursion-free) higher-order functional programming language with local store.},
	language = {en},
	booktitle = {Programming {Languages} and {Systems}},
	publisher = {Springer},
	author = {Ghica, Dan R. and Smith, Alex I.},
	editor = {Shao, Zhong},
	year = {2014},
	keywords = {Type System, Derivation Tree, Linear Logic, Resource Action, Type Inference},
	pages = {331--350},
	file = {Full Text PDF:C\:\\Users\\mhuisi\\Zotero\\storage\\87HN8VYC\\Ghica and Smith - 2014 - Bounded Linear Types in a Resource Semiring.pdf:application/pdf},
}

@incollection{hutchison_bounded_2014,
	address = {Berlin, Heidelberg},
	title = {Bounded {Linear} {Types} in a {Resource} {Semiring}},
	volume = {8410},
	isbn = {978-3-642-54832-1 978-3-642-54833-8},
	url = {http://link.springer.com/10.1007/978-3-642-54833-8_18},
	abstract = {Bounded linear types have proved to be useful for automated resource analysis and control in functional programming languages. In this paper we introduce a bounded linear typing discipline on a general notion of resource which can be modeled in a semiring. For this type system we provide both a general type-inference procedure, parameterized by the decision procedure of the semiring equational theory, and a (coherent) categorical semantics. This could be a useful type-theoretic and denotational framework for resource-sensitive compilation, and it represents a generalization of several existing type systems. As a nontrivial instance, motivated by hardware compilation, we present a complex new application to calculating and controlling timing of execution in a (recursion-free) higher-order functional programming language with local store.},
	language = {en},
	urldate = {2023-02-22},
	booktitle = {Programming {Languages} and {Systems}},
	publisher = {Springer Berlin Heidelberg},
	author = {Ghica, Dan R. and Smith, Alex I.},
	editor = {Hutchison, David and Kanade, Takeo and Kittler, Josef and Kleinberg, Jon M. and Mattern, Friedemann and Mitchell, John C. and Naor, Moni and Nierstrasz, Oscar and Pandu Rangan, C. and Steffen, Bernhard and Sudan, Madhu and Terzopoulos, Demetri and Tygar, Doug and Vardi, Moshe Y. and Weikum, Gerhard and Shao, Zhong},
	year = {2014},
	doi = {10.1007/978-3-642-54833-8_18},
	note = {Series Title: Lecture Notes in Computer Science},
	pages = {331--350},
	file = {Ghica and Smith - 2014 - Bounded Linear Types in a Resource Semiring.pdf:C\:\\Users\\mhuisi\\Zotero\\storage\\A733RYHZ\\Ghica and Smith - 2014 - Bounded Linear Types in a Resource Semiring.pdf:application/pdf},
}

@article{orchard_quantitative_2019,
	title = {Quantitative {Program} {Reasoning} with {Graded} {Modal} {Types}},
	volume = {3},
	doi = {10.1145/3341714},
	abstract = {In programming, some data acts as a resource (e.g., file handles, channels) subject to usage constraints. This poses a challenge to software correctness as most languages are agnostic to constraints on data. The approach of linear types provides a partial remedy, delineating data into resources to be used but never copied or discarded, and unconstrained values. Bounded Linear Logic provides a more fine-grained approach, quantifying non-linear use via an indexed-family of modalities. Recent work on coeffect types generalises this idea to graded comonads, providing type systems which can capture various program properties. Here, we propose the umbrella notion of graded modal types, encompassing coeffect types and dual notions of type-based effect reasoning via graded monads. In combination with linear and indexed types, we show that graded modal types provide an expressive type theory for quantitative program reasoning, advancing the reach of type systems to capture and verify a broader set of program properties. We demonstrate this approach via a type system embodied in a fully-fledged functional language called Granule, exploring various examples.},
	number = {ICFP},
	journal = {Proceedings of the ACM on Programming Languages},
	author = {Orchard, Dominic and Liepelt, Vilem-Benjamin and Eades III, Harley},
	month = jul,
	year = {2019},
	keywords = {coeffects, graded modal types, implementation, linear types},
	pages = {110:1--110:30},
	file = {Full Text PDF:C\:\\Users\\mhuisi\\Zotero\\storage\\Q3ZRR64Q\\Orchard et al. - 2019 - Quantitative program reasoning with graded modal t.pdf:application/pdf},
}

@article{harrington_uniqueness_2006,
	series = {Algebraic {Methods} in {Language} {Processing}},
	title = {Uniqueness logic},
	volume = {354},
	issn = {0304-3975},
	doi = {10.1016/j.tcs.2005.11.006},
	abstract = {A uniqueness type system is used to distinguish values which are referenced at most once from values which may be referenced an arbitrary number of times in a program. Uniqueness type systems are used in the Clean and Mercury programming languages to provide efficiently updatable data-structures and I/O without compromising referential transparency. In this paper we establish a Curry–Howard–Lambek equivalence between a form of uniqueness types and a ‘resource-sensitive’ logic. This logic is similar to intuitionistic linear logic, however the ∘ modality, which moderates the structural rules in the antecedent in the same way as !, is introduced via the dual ? rules. We discuss the categorical proof theory and models of this new logic, as well as its computational interpretation.},
	language = {en},
	number = {1},
	journal = {Theoretical Computer Science},
	author = {Harrington, Dana},
	month = mar,
	year = {2006},
	keywords = {Category theory, Functional programming, Linear logic, Semantics, Type systems},
	pages = {24--41},
	file = {ScienceDirect Full Text PDF:C\:\\Users\\mhuisi\\Zotero\\storage\\77IMBEZ4\\Harrington - 2006 - Uniqueness logic.pdf:application/pdf;ScienceDirect Snapshot:C\:\\Users\\mhuisi\\Zotero\\storage\\LJ8K93XB\\S0304397505008522.html:text/html},
}

@inproceedings{boyland_checking_2003,
	address = {Berlin, Heidelberg},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Checking {Interference} with {Fractional} {Permissions}},
	isbn = {978-3-540-44898-3},
	doi = {10.1007/3-540-44898-5_4},
	abstract = {We describe a type system for checking interference using the concept of linear capabilities (which we call “permissions”). Our innovations include the concept of “fractional” permissions: reads can be permitted with fractional permissions whereas writes require complete permissions. This distinction expresses the fact that reads on the same state do not conflict with each other. One may give shared read access at one point while still retaining write permission afterwards. We give an operational semantics of a simple imperative language with structured parallelism and prove that the permission system enables parallelism to proceed with deterministic results.},
	language = {en},
	booktitle = {Static {Analysis}},
	publisher = {Springer},
	author = {Boyland, John},
	editor = {Cousot, Radhia},
	year = {2003},
	keywords = {Alias Analysis, Operational Semantic, Parallel Composition, Permission System, Separation Logic},
	pages = {55--72},
	file = {Full Text PDF:C\:\\Users\\mhuisi\\Zotero\\storage\\Q8ZY75UY\\Boyland - 2003 - Checking Interference with Fractional Permissions.pdf:application/pdf},
}

@inproceedings{honda_types_1993,
	address = {Berlin, Heidelberg},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Types for {Dyadic} {Interaction}},
	isbn = {978-3-540-47968-0},
	doi = {10.1007/3-540-57208-2_35},
	abstract = {We formulate a typed formalism for concurrency where types denote freely composable structure of dyadic interaction in the symmetric scheme. The resulting calculus is a typed reconstruction of name passing process calculi. Systems with both the explicit and implicit typing disciplines, where types form a simple hierarchy of types, are presented, which are proved to be in accordance with each other. A typed variant of bisimilarity is formulated and it is shown that typed β-equality has a clean embedding in the bisimilarity. Name reference structure induced by the simple hierarchy of types is studied, which fully characterises the typable terms in the set of untyped terms. It turns out that the name reference structure results in the deadlock-free property for a subset of terms with a certain regular structure, showing behavioural significance of the simple type discipline.},
	language = {en},
	booktitle = {{CONCUR}'93},
	publisher = {Springer},
	author = {Honda, Kohei},
	year = {1993},
	keywords = {Atomic Type, Constant Symbol, Dyadic Interaction, Functional Type, Reference Structure},
	pages = {509--523},
	file = {Full Text PDF:C\:\\Users\\mhuisi\\Zotero\\storage\\49ILPE6C\\Honda - 1993 - Types for dyadic interaction.pdf:application/pdf},
}

@article{shi_linear_2013,
	series = {Special section on software evolution, adaptability, and maintenance \& {Special} section on the {Brazilian} {Symposium} on {Programming} {Languages}},
	title = {A linear type system for multicore programming in {ATS}},
	volume = {78},
	issn = {0167-6423},
	doi = {10.1016/j.scico.2012.09.005},
	abstract = {In this day and age of multicore architectures, programming language support is in urgent need for constructing programs that can take great advantage of machines with multiple cores. We present in this paper an approach to safe multicore programming in ATS, a recently developed functional programming language that supports both linear and dependent types. In particular, we formalize a type system capable of guaranteeing safe manipulation of resources on multicore machines and establish its soundness. We also provide concrete examples as well as experimental results in support of the practicality of the presented approach to multicore programming.},
	language = {en},
	number = {8},
	journal = {Science of Computer Programming},
	author = {Shi, Rui and Xi, Hongwei},
	month = aug,
	year = {2013},
	keywords = {Type systems, ATS, Linear types, Multicore},
	pages = {1176--1192},
	file = {ScienceDirect Full Text PDF:C\:\\Users\\mhuisi\\Zotero\\storage\\LNBMW3ES\\Shi and Xi - 2013 - A linear type system for multicore programming in .pdf:application/pdf;ScienceDirect Snapshot:C\:\\Users\\mhuisi\\Zotero\\storage\\NTSYFGCS\\S0167642312001700.html:text/html},
}

@book{nipkow_isabellehol_2002,
	address = {Berlin, Heidelberg},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Isabelle/{HOL}},
	volume = {2283},
	isbn = {978-3-540-43376-7 978-3-540-45949-1},
	publisher = {Springer},
	editor = {Nipkow, Tobias and Wenzel, Markus and Paulson, Lawrence C. and Goos, Gerhard and Hartmanis, Juris and van Leeuwen, Jan},
	year = {2002},
	doi = {10.1007/3-540-45949-9},
	keywords = {Formal Methods, Formal Reasoning, Formal Specification, Formal Verification, Functional Programming, Higher-Order Logic, Interactive Proof Systems, Isabelle, logic, predicate logic, Proof Assistants, Proof Theory, Theorem Proving, Type Theory, verification},
	file = {Full Text PDF:C\:\\Users\\mhuisi\\Zotero\\storage\\J9CZUB7A\\Nipkow et al. - 2002 - IsabelleHOL.pdf:application/pdf},
}

@inproceedings{henriksen_futhark_2017,
	address = {New York, NY, USA},
	series = {{PLDI} 2017},
	title = {Futhark: {Purely} {Functional} {GPU}-{Programming} with {Nested} {Parallelism} and {In}-{Place} {Array} {Updates}},
	isbn = {978-1-4503-4988-8},
	shorttitle = {Futhark},
	doi = {10.1145/3062341.3062354},
	abstract = {Futhark is a purely functional data-parallel array language that offers a machine-neutral programming model and an optimising compiler that generates OpenCL code for GPUs. This paper presents the design and implementation of three key features of Futhark that seek a suitable middle ground with imperative approaches. First, in order to express efficient code inside the parallel constructs, we introduce a simple type system for in-place updates that ensures referential transparency and supports equational reasoning. Second, we furnish Futhark with parallel operators capable of expressing efficient strength-reduced code, along with their fusion rules. Third, we present a flattening transformation aimed at enhancing the degree of parallelism that (i) builds on loop interchange and distribution but uses higher-order reasoning rather than array-dependence analysis, and (ii) still allows further locality-of-reference optimisations. Finally, an evaluation on 16 benchmarks demonstrates the impact of the language and compiler features and shows application-level performance competitive with hand-written GPU code.},
	booktitle = {Proceedings of the 38th {ACM} {SIGPLAN} {Conference} on {Programming} {Language} {Design} and {Implementation}},
	publisher = {Association for Computing Machinery},
	author = {Henriksen, Troels and Serup, Niels G. W. and Elsman, Martin and Henglein, Fritz and Oancea, Cosmin E.},
	month = jun,
	year = {2017},
	keywords = {compilers, functional language, GPGPU, parallel},
	pages = {556--571},
	file = {Full Text PDF:C\:\\Users\\mhuisi\\Zotero\\storage\\TWSBU89A\\Henriksen et al. - 2017 - Futhark purely functional GPU-programming with ne.pdf:application/pdf},
}

@article{radanne_kindly_2020,
	title = {Kindly {Bent} to {Free} {Us}},
	volume = {4},
	doi = {10.1145/3408985},
	abstract = {Systems programming often requires the manipulation of resources like file handles, network connections, or dynamically allocated memory. Programmers need to follow certain protocols to handle these resources correctly. Violating these protocols causes bugs ranging from type mismatches over data races to use-after-free errors and memory leaks. These bugs often lead to security vulnerabilities. While statically typed programming languages guarantee type soundness and memory safety by design, most of them do not address issues arising from improper handling of resources. An important step towards handling resources is the adoption of linear and affine types that enforce single-threaded resource usage. However, the few languages supporting such types require heavy type annotations. We present Affe, an extension of ML that manages linearity and affinity properties using kinds and constrained types. In addition Affe supports the exclusive and shared borrowing of affine resources, inspired by features of Rust. Moreover, Affe retains the defining features of the ML family: it is an impure, strict, functional expression language with complete principal type inference and type abstraction. does not require any linearity annotations in expressions and supports common functional programming idioms.},
	number = {ICFP},
	journal = {Proceedings of the ACM on Programming Languages},
	author = {Radanne, Gabriel and Saffrich, Hannes and Thiemann, Peter},
	month = aug,
	year = {2020},
	keywords = {Functional programming, Linear types, Ownership, Type inference},
	pages = {103:1--103:29},
	file = {Full Text PDF:C\:\\Users\\mhuisi\\Zotero\\storage\\35NMC683\\Radanne et al. - 2020 - Kindly bent to free us.pdf:application/pdf},
}

@inproceedings{mazurak_lightweight_2010,
	address = {Madrid Spain},
	title = {Lightweight {Linear} {Types} in {System} {F}°},
	isbn = {978-1-60558-891-9},
	doi = {10.1145/1708016.1708027},
	abstract = {We present System F◦, an extension of System F that uses kinds to distinguish between linear and unrestricted types, simplifying the use of linearity for general-purpose programming. We demonstrate through examples how System F◦ can elegantly express many useful protocols, and we prove that any protocol representable as a DFA can be encoded as an F◦ type. We supply mechanized proofs of System F◦’s soundness and parametricity properties, along with a nonstandard operational semantics that formalizes common intuitions about linearity and aids in reasoning about protocols.},
	language = {en},
	booktitle = {Proceedings of the 5th {ACM} {SIGPLAN} workshop on {Types} in language design and implementation},
	publisher = {ACM},
	author = {Mazurak, Karl and Zhao, Jianzhou and Zdancewic, Steve},
	month = jan,
	year = {2010},
	pages = {77--88},
	file = {Mazurak et al. - 2010 - Lightweight linear types in system f°.pdf:C\:\\Users\\mhuisi\\Zotero\\storage\\AIBKVWZQ\\Mazurak et al. - 2010 - Lightweight linear types in system f°.pdf:application/pdf},
}

@article{morris_best_2016,
	title = {The {Best} of {Both} {Worlds}: {Linear} {Functional} {Programming} without {Compromise}},
	volume = {51},
	issn = {0362-1340},
	shorttitle = {The best of both worlds},
	doi = {10.1145/3022670.2951925},
	abstract = {We present a linear functional calculus with both the safety guarantees expressible with linear types and the rich language of combinators and composition provided by functional programming. Unlike previous combinations of linear typing and functional programming, we compromise neither the linear side (for example, our linear values are first-class citizens of the language) nor the functional side (for example, we do not require duplicate definitions of compositions for linear and unrestricted functions). To do so, we must generalize abstraction and application to encompass both linear and unrestricted functions. We capture the typing of the generalized constructs with a novel use of qualified types. Our system maintains the metatheoretic properties of the theory of qualified types, including principal types and decidable type inference. Finally, we give a formal basis for our claims of expressiveness, by showing that evaluation respects linearity, and that our language is a conservative extension of existing functional calculi.},
	number = {9},
	journal = {ACM SIGPLAN Notices},
	author = {Morris, J. Garrett},
	month = sep,
	year = {2016},
	keywords = {linear types, qualified types, substructural types},
	pages = {448--461},
	file = {Full Text PDF:C\:\\Users\\mhuisi\\Zotero\\storage\\JKD3KKJF\\Morris - 2016 - The best of both worlds linear functional program.pdf:application/pdf},
}

@article{balabonski_design_2016,
	title = {The {Design} and {Formalization} of {Mezzo}, a {Permission}-{Based} {Programming} {Language}},
	volume = {38},
	issn = {0164-0925},
	doi = {10.1145/2837022},
	abstract = {The programming language Mezzo is equipped with a rich type system that controls aliasing and access to mutable memory. We give a comprehensive tutorial overview of the language. Then we present a modular formalization of Mezzo’s core type system, in the form of a concurrent λ-calculus, which we successively extend with references, locks, and adoption and abandon, a novel mechanism that marries Mezzo’s static ownership discipline with dynamic ownership tests. We prove that well-typed programs do not go wrong and are data-race free. Our definitions and proofs are machine checked.},
	number = {4},
	journal = {ACM Transactions on Programming Languages and Systems},
	author = {Balabonski, Thibaut and Pottier, François and Protzenko, Jonathan},
	month = aug,
	year = {2016},
	keywords = {Aliasing, concurrency, ownership, side effects, static type systems},
	pages = {14:1--14:94},
	file = {Full Text PDF:C\:\\Users\\mhuisi\\Zotero\\storage\\HYQZI95I\\Balabonski et al. - 2016 - The Design and Formalization of Mezzo, a Permissio.pdf:application/pdf},
}

@inproceedings{deline_enforcing_2001,
	address = {New York, NY, USA},
	series = {{PLDI} '01},
	title = {Enforcing high-level protocols in low-level software},
	isbn = {978-1-58113-414-8},
	doi = {10.1145/378795.378811},
	booktitle = {Proceedings of the {ACM} {SIGPLAN} 2001 conference on {Programming} language design and implementation},
	publisher = {Association for Computing Machinery},
	author = {DeLine, Robert and Fähndrich, Manuel},
	year = {2001},
	pages = {59--69},
}

@article{garcia_foundations_2014,
	title = {Foundations of {Typestate}-{Oriented} {Programming}},
	volume = {36},
	issn = {0164-0925},
	doi = {10.1145/2629609},
	abstract = {Typestate reflects how the legal operations on imperative objects can change at runtime as their internal state changes. A typestate checker can statically ensure, for instance, that an object method is only called when the object is in a state for which the operation is well defined. Prior work has shown how modular typestate checking can be achieved thanks to access permissions and state guarantees. However, typestate was not treated as a primitive language concept: typestate checkers are an additional verification layer on top of an existing language. In contrast, a typestate-oriented programming (TSOP) language directly supports expressing typestates. For example, in the Plaid programming language, the typestate of an object directly corresponds to its class, and that class can change dynamically. Plaid objects have not only typestate-dependent interfaces but also typestate-dependent behaviors and runtime representations. This article lays foundations for TSOP by formalizing a nominal object-oriented language with mutable state that integrates typestate change and typestate checking as primitive concepts. We first describe a statically typed language—Featherweight Typestate (FT)—where the types of object references are augmented with access permissions and state guarantees. We describe a novel flow-sensitive permission-based type system for FT. Because static typestate checking is still too rigid for some applications, we then extend this language into a gradually typed language—Gradual Featherweight Typestate (GFT). This language extends the notion of gradual typing to account for typestate: gradual typestate checking seamlessly combines static and dynamic checking by automatically inserting runtime checks into programs. The gradual type system of GFT allows programmers to write dynamically safe code even when the static type checker can only partly verify it.},
	number = {4},
	journal = {ACM Transactions on Programming Languages and Systems},
	author = {Garcia, Ronald and Tanter, Éric and Wolff, Roger and Aldrich, Jonathan},
	month = oct,
	year = {2014},
	keywords = {Access permissions, gradual typing, types, typestates},
	pages = {12:1--12:44},
	file = {Full Text PDF:C\:\\Users\\mhuisi\\Zotero\\storage\\TKEJCKUB\\Garcia et al. - 2014 - Foundations of Typestate-Oriented Programming.pdf:application/pdf},
}

@incollection{barrett_satisfiability_2018,
	address = {Cham},
	title = {Satisfiability {Modulo} {Theories}},
	isbn = {978-3-319-10575-8},
	abstract = {Satisfiability Modulo Theories (SMT) refers to the problem of determining whether a first-order formula is satisfiable with respect to some logical theory. Solvers based on SMT are used as back-end engines in model-checking applications such as bounded, interpolation-based, and predicate-abstraction-based model checking. After a brief illustration of these uses, we survey the predominant techniques for solving SMT problems with an emphasis on the lazy approach, in which a propositional satisfiability (SAT) solver is combined with one or more theory solvers. We discuss the architecture of a lazy SMT solver, give examples of theory solvers, show how to combine such solvers modularly, and mention several extensions of the lazy approach. We also briefly describe the eager approach in which the SMT problem is reduced to a SAT problem. Finally, we discuss how the basic framework for determining satisfiability can be extended with additional functionality such as producing models, proofs, unsatisfiable cores, and interpolants.},
	language = {en},
	booktitle = {Handbook of {Model} {Checking}},
	publisher = {Springer International Publishing},
	author = {Barrett, Clark and Tinelli, Cesare},
	year = {2018},
	doi = {10.1007/978-3-319-10575-8_11},
	pages = {305--343},
	file = {Full Text PDF:C\:\\Users\\mhuisi\\Zotero\\storage\\EMQ4VEH2\\Barrett and Tinelli - 2018 - Satisfiability Modulo Theories.pdf:application/pdf},
}

@inproceedings{lattner_llvm_2004,
	title = {{LLVM}: {A} {Compilation} {Framework} for {Lifelong} {Program} {Analysis} \& {Transformation}},
	shorttitle = {{LLVM}},
	doi = {10.1109/CGO.2004.1281665},
	abstract = {We describe LLVM (low level virtual machine), a compiler framework designed to support transparent, lifelong program analysis and transformation for arbitrary programs, by providing high-level information to compiler transformations at compile-time, link-time, run-time, and in idle time between runs. LLVM defines a common, low-level code representation in static single assignment (SSA) form, with several novel features: a simple, language-independent type-system that exposes the primitives commonly used to implement high-level language features; an instruction for typed address arithmetic; and a simple mechanism that can be used to implement the exception handling features of high-level languages (and setjmp/longjmp in C) uniformly and efficiently. The LLVM compiler framework and code representation together provide a combination of key capabilities that are important for practical, lifelong analysis and transformation of programs. To our knowledge, no existing compilation approach provides all these capabilities. We describe the design of the LLVM representation and compiler framework, and evaluate the design in three ways: (a) the size and effectiveness of the representation, including the type information it provides; (b) compiler performance for several interprocedural problems; and (c) illustrative examples of the benefits LLVM provides for several challenging compiler problems.},
	booktitle = {International {Symposium} on {Code} {Generation} and {Optimization}, 2004. {CGO} 2004.},
	author = {Lattner, C. and Adve, V.},
	month = mar,
	year = {2004},
	keywords = {Algorithm design and analysis, Application software, Arithmetic, High level languages, Information analysis, Performance analysis, Program processors, Runtime, Software safety, Virtual machining},
	pages = {75--86},
	file = {Full Text:C\:\\Users\\mhuisi\\Zotero\\storage\\LHBHXA4D\\Lattner and Adve - 2004 - LLVM a compilation framework for lifelong program.pdf:application/pdf;IEEE Xplore Abstract Record:C\:\\Users\\mhuisi\\Zotero\\storage\\HFZXZDVS\\1281665.html:text/html},
}

@inproceedings{cocke_global_1970,
	address = {New York, NY, USA},
	title = {Global {Common} {Subexpression} {Elimination}},
	isbn = {978-1-4503-7386-9},
	doi = {10.1145/800028.808480},
	abstract = {When considering compiler optimization, there are two questions that immediately come to mind; one, why and to what extent is optimization necessary and two, to what extent is it possible. When considering the second question, one might immediately become discouraged since it is well known that the program equivalency problem is recursively unsolvable. It is, of course, clear from this that there will never be techniques for generating a completely optimum program. These unsolvability results, however, do not preclude the possibility of ad hoc techniques for program improvement or even a partial theory which produces a class of equivalent programs optimized in varying degrees. The reasons why optimization is required seem to me to fall in two major categories. The first I will call “local” and the second “global”.},
	booktitle = {Proceedings of a symposium on {Compiler} optimization},
	publisher = {Association for Computing Machinery},
	author = {Cocke, John},
	month = jul,
	year = {1970},
	pages = {20--24},
	file = {Full Text PDF:C\:\\Users\\mhuisi\\Zotero\\storage\\ZX7PNQ7D\\Cocke - 1970 - Global common subexpression elimination.pdf:application/pdf},
}

@inproceedings{johnsson_lambda_1985,
	address = {Berlin, Heidelberg},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Lambda {Lifting}: {Transforming} {Programs} to {Recursive} {Equations}},
	isbn = {978-3-540-39677-2},
	shorttitle = {Lambda lifting},
	doi = {10.1007/3-540-15975-4_37},
	abstract = {Lambda lifting is a technique for transforming a functional program with local function definitions, possibly with free variables in the function definitions, into a program consisting only of global function (combinator) definitions which will be used as rewrite rules. Different ways of doing lambda lifting are presented, as well as reasons for rejecting or selecting the method used in our Lazy ML compiler. A functional program implementing the chosen algorithm is given.},
	language = {en},
	booktitle = {Functional {Programming} {Languages} and {Computer} {Architecture}},
	publisher = {Springer},
	author = {Johnsson, Thomas},
	editor = {Jouannaud, Jean-Pierre},
	year = {1985},
	pages = {190--203},
	file = {Full Text PDF:C\:\\Users\\mhuisi\\Zotero\\storage\\4426TNRT\\Johnsson - 1985 - Lambda lifting Transforming programs to recursive.pdf:application/pdf},
}

@phdthesis{tejiscak_erasure_2019,
	type = {{PhD} thesis},
	title = {Erasure in {Dependently} {Typed} {Programming}},
	url = {https://ziman.functor.sk/media/thesis.pdf},
	language = {English},
	urldate = {2023-03-12},
	school = {University of St Andrews},
	author = {Tejiščák, Matúš},
	month = mar,
	year = {2019},
}

@inproceedings{augustsson_implementing_1993,
	address = {Copenhagen Denmark},
	title = {Implementing {Haskell} overloading},
	isbn = {978-0-89791-595-3},
	doi = {10.1145/165180.165191},
	language = {en},
	booktitle = {Proceedings of the conference on {Functional} programming languages and computer architecture},
	publisher = {ACM},
	author = {Augustsson, Lennart},
	month = jul,
	year = {1993},
	pages = {65--73},
}

@article{jones_secrets_2002,
	title = {Secrets of the {Glasgow} {Haskell} {Compiler} inliner},
	volume = {12},
	issn = {1469-7653, 0956-7968},
	doi = {10.1017/S0956796802004331},
	abstract = {Higher-order languages such as Haskell encourage the programmer to build abstractions by 
composing functions. A good compiler must inline many of these calls to recover an efficiently 
executable program. In principle, inlining is dead simple: just replace the call of a function by 
an instance of its body. But any compiler-writer will tell you that inlining is a black art, full 
of delicate compromises that work together to give good performance without unnecessary 
code bloat. The purpose of this paper is, therefore, to articulate the key lessons we learned 
from a full-scale “production” inliner, the one used in the Glasgow Haskell compiler. We 
focus mainly on the algorithmic aspects, but we also provide some indicative measurements 
to substantiate the importance of various aspects of the inliner.},
	language = {en},
	number = {4-5},
	journal = {Journal of Functional Programming},
	author = {Jones, Simon Peyton and Marlow, Simon},
	month = jul,
	year = {2002},
	note = {Publisher: Cambridge University Press},
	pages = {393--434},
	file = {Full Text PDF:C\:\\Users\\mhuisi\\Zotero\\storage\\TR3VZVKH\\Jones and Marlow - 2002 - Secrets of the Glasgow Haskell Compiler inliner.pdf:application/pdf},
}

@article{sabry_reasoning_1993,
	title = {Reasoning about programs in continuation-passing style},
	volume = {6},
	issn = {1573-0557},
	url = {https://doi.org/10.1007/BF01019462},
	doi = {10.1007/BF01019462},
	abstract = {Plotkin's λv-calculus for call-by-value programs is weaker than the λβη-calculus for the same programs in continuation-passing style (CPS). To identify the call-by-value axioms that correspond to βη on CPS terms, we define a new CPS transformation and an inverse mapping, both of which are interesting in their own right. Using the new CPS transformation, we determine the precise language of CPS terms closed under βη-transformations, as well as the call-by-value axioms that correspond to the so-called administrative βη-reductions on CPS terms. Using the inverse mapping, we map the remaining β and η equalities on CPS terms to axioms on call-by-value terms. On the pure (constant free) set of Λ-terms, the resulting set of axioms is equivalent to Moggi's computational λ-calculus. If the call-by-value language includes the control operatorsabort andcall-with-current-continuation, the axioms are equivalent to an extension of Felleisenet al.'s λv-C-calculus and to the equational subtheory of Talcott's logic IOCC.},
	language = {en},
	number = {3},
	urldate = {2023-03-12},
	journal = {LISP and Symbolic Computation},
	author = {Sabry, AMR and Felleisen, Matthias},
	month = nov,
	year = {1993},
	keywords = {continuation-passing style, CPS transformations, inverse CPS transformations, IOCC, λ v -C-calculus, λ v -calculus, λ-calculus},
	pages = {289--360},
	file = {Full Text PDF:C\:\\Users\\mhuisi\\Zotero\\storage\\LB9W9UXF\\Sabry and Felleisen - 1993 - Reasoning about programs in continuation-passing s.pdf:application/pdf},
}

@article{flanagan_essence_1993,
	title = {The essence of compiling with continuations},
	volume = {28},
	issn = {0362-1340},
	url = {https://doi.org/10.1145/173262.155113},
	doi = {10.1145/173262.155113},
	abstract = {In order to simplify the compilation process, many compilers for higher-order languages use the continuation-passing style (CPS) transformation in a first phase to generate an intermediate representation of the source program. The salient aspect of this intermediate form is that all procedures take an argument that represents the rest of the computation (the “continuation”). Since the nai¨ve CPS transformation considerably increases the size of programs, CPS compilers perform reductions to produce a more compact intermediate representation. Although often implemented as a part of the CPS transformation, this step is conceptually a second phase. Finally, code generators for typical CPS compilers treat continuations specially in order to optimize the interpretation of continuation parameters. A thorough analysis of the abstract machine for CPS terms show that the actions of the code generator invert the nai¨ve CPS translation step. Put differently, the combined effect of the three phases is equivalent to a source-to-source transformation that simulates the compaction phase. Thus, fully developed CPS compilers do not need to employ the CPS transformation but can achieve the same results with a simple source-level transformation.},
	number = {6},
	urldate = {2023-03-12},
	journal = {ACM SIGPLAN Notices},
	author = {Flanagan, Cormac and Sabry, Amr and Duba, Bruce F. and Felleisen, Matthias},
	month = jun,
	year = {1993},
	pages = {237--247},
	file = {Full Text PDF:C\:\\Users\\mhuisi\\Zotero\\storage\\YKSCANI3\\Flanagan et al. - 1993 - The essence of compiling with continuations.pdf:application/pdf},
}

@article{maurer_compiling_2017,
	title = {Compiling without {Continuations}},
	volume = {52},
	issn = {0362-1340},
	doi = {10.1145/3140587.3062380},
	abstract = {Many fields of study in compilers give rise to the concept of a join point—a place where different execution paths come together. Join points are often treated as functions or continuations, but we believe it is time to study them in their own right. We show that adding join points to a direct-style functional intermediate language is a simple but powerful change that allows new optimizations to be performed, including a significant improvement to list fusion. Finally, we report on recent work on adding join points to the intermediate language of the Glasgow Haskell Compiler.},
	number = {6},
	journal = {ACM SIGPLAN Notices},
	author = {Maurer, Luke and Downen, Paul and Ariola, Zena M. and Peyton Jones, Simon},
	month = jun,
	year = {2017},
	keywords = {ANF, CPS, GHC, Haskell, intermediate languages, list fusion},
	pages = {482--494},
	file = {Full Text PDF:C\:\\Users\\mhuisi\\Zotero\\storage\\Q9LXU2V8\\Maurer et al. - 2017 - Compiling without continuations.pdf:application/pdf},
}

@inproceedings{henglein_formally_1994,
	address = {New York, NY, USA},
	series = {{POPL} '94},
	title = {Formally {Optimal} {Boxing}},
	isbn = {978-0-89791-636-3},
	doi = {10.1145/174675.177874},
	abstract = {An important implementation decision in polymorphically typed functional programming language is whether to represent data in boxed or unboxed form and when to transform them from one representation to the other. Using a language with explicit representation types and boxing/unboxing operations we axiomatize equationally the set of all explicitly boxed versions, called completions, of a given source program. In a two-stage process we give some of the equations a rewriting interpretation that captures eliminating boxing/unboxing operations without relying on a specific implementation or even semantics of the underlying language. The resulting reduction systems operate on congruence classes of completions defined by the remaining equations E, which can be understood as moving boxing/unboxing operations along data flow paths in the source program. We call a completion eopt formally optimal if every other completion for the same program (and at the same representation type) reduces to eopt under this two-stage reduction. We show that every source program has formally optimal completions, which are unique modulo E. This is accomplished by first “polarizing” the equations in E and orienting them to obtain two canonical (confluent and strongly normalizing) rewriting systems. The completions produced by Leroy's and Poulsen's algorithms are generally not formally optimal in our sense. The rewriting systems have been implemented and applied to some simple Standard ML programs. Our results show that the amount of boxing and unboxing operations is also in practice substantially reduced in comparison to Leroy's completions. This analysis is intended to be integrated into Tofte's region-based implementation of Standard ML currently underway at DIKU.},
	booktitle = {Proceedings of the 21st {ACM} {SIGPLAN}-{SIGACT} symposium on {Principles} of programming languages},
	publisher = {Association for Computing Machinery},
	author = {Henglein, Fritz and Jørgensen, Jesper},
	month = feb,
	year = {1994},
	keywords = {polymorphism, representation analysis, type inference},
	pages = {213--226},
	file = {Full Text PDF:C\:\\Users\\mhuisi\\Zotero\\storage\\L2YR427S\\Henglein and Jørgensen - 1994 - Formally optimal boxing.pdf:application/pdf},
}

@article{altenkirch_monads_2015,
	title = {Monads need not be endofunctors},
	volume = {11},
	issn = {18605974},
	doi = {10.2168/LMCS-11(1:3)2015},
	abstract = {We introduce a generalization of monads, called relative monads, allowing for underlying functors between different categories. Examples include finite-dimensional vector spaces, untyped and typed lambda-calculus syntax and indexed containers. We show that the Kleisli and Eilenberg-Moore constructions carry over to relative monads and are related to relative adjunctions. Under reasonable assumptions, relative monads are monoids in the functor category concerned and extend to monads, giving rise to a coreflection between relative monads and monads. Arrows are also an instance of relative monads.},
	number = {1},
	journal = {Logical Methods in Computer Science},
	author = {Altenkirch, Thosten and Chapman, James and Uustalu, Tarmo},
	month = mar,
	year = {2015},
	note = {arXiv:1412.7148 [cs, math]},
	keywords = {Computer Science - Programming Languages, Computer Science - Logic in Computer Science, Mathematics - Category Theory},
	pages = {3},
	file = {arXiv Fulltext PDF:C\:\\Users\\mhuisi\\Zotero\\storage\\XSZ785TE\\Altenkirch et al. - 2015 - Monads need not be endofunctors.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\mhuisi\\Zotero\\storage\\DSMIHUN2\\1412.html:text/html},
}

@article{allen_program_1976,
	title = {A {Program} {Data} {Flow} {Analysis} {Procedure}},
	volume = {19},
	issn = {0001-0782},
	doi = {10.1145/360018.360025},
	abstract = {The global data relationships in a program can be exposed and codified by the static analysis methods described in this paper. A procedure is given which determines all the definitions which can possibly “reach” each node of the control flow graph of the program and all the definitions that are “live” on each edge of the graph. The procedure uses an “interval” ordered edge listing data structure and handles reducible and irreducible graphs indistinguishably.},
	number = {3},
	journal = {Communications of the ACM},
	author = {Allen, F. E. and Cocke, J.},
	month = mar,
	year = {1976},
	keywords = {compilers, algorithms, data flow analysis, flow graphs, program optimization},
	pages = {137},
	file = {Full Text PDF:C\:\\Users\\mhuisi\\Zotero\\storage\\59EPISLQ\\Allen and Cocke - 1976 - A program data flow analysis procedure.pdf:application/pdf},
}

@inproceedings{cousot_abstract_1977,
	address = {New York, NY, USA},
	series = {{POPL} '77},
	title = {Abstract interpretation: a unified lattice model for static analysis of programs by construction or approximation of fixpoints},
	isbn = {978-1-4503-7350-0},
	shorttitle = {Abstract interpretation},
	doi = {10.1145/512950.512973},
	abstract = {A program denotes computations in some universe of objects. Abstract interpretation of programs consists in using that denotation to describe computations in another universe of abstract objects, so that the results of abstract execution give some information on the actual computations. An intuitive example (which we borrow from Sintzoff [72]) is the rule of signs. The text -1515 * 17 may be understood to denote computations on the abstract universe \{(+), (-), (±)\} where the semantics of arithmetic operators is defined by the rule of signs. The abstract execution -1515 * 17 → -(+) * (+) → (-) * (+) → (-), proves that -1515 * 17 is a negative number. Abstract interpretation is concerned by a particular underlying structure of the usual universe of computations (the sign, in our example). It gives a summary of some facets of the actual executions of a program. In general this summary is simple to obtain but inaccurate (e.g. -1515 + 17 → -(+) + (+) → (-) + (+) → (±)). Despite its fundamentally incomplete results abstract interpretation allows the programmer or the compiler to answer questions which do not need full knowledge of program executions or which tolerate an imprecise answer, (e.g. partial correctness proofs of programs ignoring the termination problems, type checking, program optimizations which are not carried in the absence of certainty about their feasibility, …).},
	booktitle = {Proceedings of the 4th {ACM} {SIGACT}-{SIGPLAN} symposium on {Principles} of programming languages},
	publisher = {Association for Computing Machinery},
	author = {Cousot, Patrick and Cousot, Radhia},
	month = jan,
	year = {1977},
	pages = {238--252},
	file = {Full Text PDF:C\:\\Users\\mhuisi\\Zotero\\storage\\7TBGTVD8\\Cousot and Cousot - 1977 - Abstract interpretation a unified lattice model f.pdf:application/pdf},
}

@unpublished{blanchet_introduction_2002,
	title = {Introduction to {Abstract} {Interpretation}},
	url = {https://bblanche.gitlabpages.inria.fr/absint.pdf},
	abstract = {We present the basic theory of abstract interpretation, and its application to static program analysis. The goal is not to give an exhaustive view of abstract interpretation, but to give enough background to make papers on abstract interpretation more understandable.},
	language = {en},
	urldate = {2023-03-19},
	author = {Blanchet, Bruno},
	month = nov,
	year = {2002},
	file = {Blanchet - Introduction to Abstract Interpretation.pdf:C\:\\Users\\mhuisi\\Zotero\\storage\\XLA84STP\\Blanchet - Introduction to Abstract Interpretation.pdf:application/pdf},
}

@inproceedings{jones_playing_2001,
	title = {Playing by the {Rules}: {Rewriting} as a practical optimisation technique in {GHC}},
	booktitle = {2001 {ACM} {SIGPLAN}},
	author = {Jones, Simon Peyton and Tolmach, Andrew and Hoare, Tony},
	year = {2001},
	pages = {203},
}

@article{niu_cost-aware_2022,
	title = {A {Cost}-{Aware} {Logical} {Framework}},
	volume = {6},
	doi = {10.1145/3498670},
	abstract = {We present calf, a cost-aware logical framework for studying quantitative aspects of functional programs. Taking inspiration from recent work that reconstructs traditional aspects of programming languages in terms of a modal account of phase distinctions, we argue that the cost structure of programs motivates a phase distinction between intension and extension. Armed with this technology, we contribute a synthetic account of cost structure as a computational effect in which cost-aware programs enjoy an internal noninterference property: input/output behavior cannot depend on cost. As a full-spectrum dependent type theory, calf presents a unified language for programming and specification of both cost and behavior that can be integrated smoothly with existing mathematical libraries available in type theoretic proof assistants. We evaluate calf as a general framework for cost analysis by implementing two fundamental techniques for algorithm analysis: the method of recurrence relations and physicist’s method for amortized analysis. We deploy these techniques on a variety of case studies: we prove a tight, closed bound for Euclid’s algorithm, verify the amortized complexity of batched queues, and derive tight, closed bounds for the sequential and parallel complexity of merge sort, all fully mechanized in the Agda proof assistant. Lastly we substantiate the soundness of quantitative reasoning in calf by means of a model construction.},
	number = {POPL},
	journal = {Proceedings of the ACM on Programming Languages},
	author = {Niu, Yue and Sterling, Jonathan and Grodin, Harrison and Harper, Robert},
	month = jan,
	year = {2022},
	keywords = {algorithm analysis, amortized analysis, behavioral verification, cost models, equational reasoning, intensional property, mechanized proof, modal type theory, noninterference, parallel algorithms, phase distinction, proof assistants, recurrence relations},
	pages = {9:1--9:31},
	file = {Full Text PDF:C\:\\Users\\mhuisi\\Zotero\\storage\\YQHQAMU9\\Niu et al. - 2022 - A cost-aware logical framework.pdf:application/pdf},
}

@misc{ullrich_counting_2020,
	title = {Counting {Immutable} {Beans}: {Reference} {Counting} {Optimized} for {Purely} {Functional} {Programming}},
	shorttitle = {Counting {Immutable} {Beans}},
	doi = {10.48550/arXiv.1908.05647},
	abstract = {Most functional languages rely on some garbage collection for automatic memory management. They usually eschew reference counting in favor of a tracing garbage collector, which has less bookkeeping overhead at runtime. On the other hand, having an exact reference count of each value can enable optimizations, such as destructive updates. We explore these optimization opportunities in the context of an eager, purely functional programming language. We propose a new mechanism for efficiently reclaiming memory used by nonshared values, reducing stress on the global memory allocator. We describe an approach for minimizing the number of reference counts updates using borrowed references and a heuristic for automatically inferring borrow annotations. We implemented all these techniques in a new compiler for an eager and purely functional programming language with support for multi-threading. Our preliminary experimental results demonstrate our approach is competitive and often outperforms state-of-the-art compilers.},
	publisher = {arXiv},
	author = {Ullrich, Sebastian and de Moura, Leonardo},
	month = mar,
	year = {2020},
	note = {arXiv:1908.05647 [cs]},
	keywords = {Computer Science - Programming Languages},
	file = {arXiv Fulltext PDF:C\:\\Users\\mhuisi\\Zotero\\storage\\C42WXIH9\\Ullrich and de Moura - 2020 - Counting Immutable Beans Reference Counting Optim.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\mhuisi\\Zotero\\storage\\4P8D6HAZ\\1908.html:text/html},
}

@misc{wadler_linear_1990,
	title = {Linear {Types} can {Change} the {World}!},
	url = {https://cs.ioc.ee/ewscs/2010/mycroft/linear-2up.pdf},
	author = {Wadler, Philip},
	year = {1990},
}

@article{brady_type-driven_2017,
	title = {Type-{Driven} {Development} of {Concurrent} {Communicating} {Systems}},
	volume = {18},
	copyright = {Copyright (c) 2017 Computer Science},
	issn = {2300-7036},
	doi = {10.7494/csci.2017.18.3.1413},
	abstract = {Modern software systems rely on communication, for example mobile applcations communicating with a central server, distributed systems coordinaing a telecommunications network, or concurrent systems handling events and processes in a desktop application. However, reasoning about concurrent prgrams is hard, since we must reason about each process and the order in which communication might happen between processes. In this paper, I describe a type-driven approach to implementing communicating concurrent programs, using the dependently typed programming language Idris. I show how the type system can be used to describe resource access protocols (such as controlling access to a file handle) and verify that programs correctly follow those prtools. Finally, I show how to use the type system to reason about the order of communication between concurrent processes, ensuring that each end of a communication channel follows a defined protocol.},
	language = {en},
	number = {3},
	journal = {Computer Science},
	author = {Brady, Edwin Charles},
	month = jul,
	year = {2017},
	note = {Number: 3},
	file = {Full Text PDF:C\:\\Users\\mhuisi\\Zotero\\storage\\US97VZFV\\Brady - 2017 - Type-driven Development of Concurrent Communicatin.pdf:application/pdf},
}
