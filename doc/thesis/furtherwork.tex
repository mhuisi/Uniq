\chapter{Future Work}\label{sec:futurework}
In this chapter, we will quickly cover work that is still left to be done in order to integrate our type theory with Lean 4, as well as work that would greatly improve the user-experience of working with the type theory.

\section{Type Inference}\label{sec:inference}
We have not covered the topic of type inference at all so far, but some amount of type inference is necessary to integrate our type theory with Lean 4. During the compilation process, the Lean 4 compiler toolchain may create additional auxiliary functions that users cannot provide type annotations for: 
\begin{itemize}
	\item In monadic control flow, Lean may create join points and other auxiliary functions to represent complex control flow (\lstinline|break|, \lstinline|continue|, early \lstinline|return|, \lstinline|if| blocks).
	\item As argued in \cref{sec:ir}, functions that act as join points may get replaced by dedicated join point instructions that callers can directly jump to.
	\item If a function does not use all of its parameters, then an auxiliary function using only live parameters is created. Note that this may occur often because of LCNF's monomorphization step, where type parameters and other instances of dependent types are erased.
\end{itemize}
Fortunately, in all of these cases, we have access to a lot of surrounding context to determine what the respective uniqueness attributes for an auxiliary function should be.

Nonetheless, it would be nice to have some amount of type inference for the uniqueness attributes of user-written functions as well. Generally, we want parameters that can be borrowed in the sense of \cref{sec:borrowing} to be shared. On the other hand, for parameters that escape, there is no principal type: Depending on whether callers have a unique or shared object at hand, they would want the parameter type to match the given attribute that they have available.

Hence, without polymorphism, one possible approach would be to infer the strongest possible type for a given function and then automatically create auxiliary functions that represent possible weakenings of this strongest possible type, the most obvious weakening being a function where all parameters are shared and the return type is shared as well.

With polymorphism, principal types may again become available and could directly be inferred if the inference algorithm is sufficiently sophisticated.

\section{Integration With Lean 4}
In \cref{sec:implementation}, we implement a type checker for our type theory and a model implementation of the IR described in \cref{sec:ir}, but do not integrate it with Lean 4 itself. In the future, the following steps need to be taken to finish the integration:
\begin{enumerate}
	\item A form of type inference that can deal with the kinds of auxiliary functions described in \cref{sec:inference} needs to be implemented.
	\item A notation to provide uniqueness annotations in types needs to be implemented. Types annotated with $*$ are unique, types without an annotation are shared. The notation should set the \lstinline|mdata| field of Lean 4's \lstinline|Expr|, which can be used to store auxiliary data.
	\item The \lstinline|mdata| field needs to be handled correctly in the compiler toolchain so that it is preserved until the type checker runs at the end of the pipeline. As of the writing of this thesis, the function that converts Lean types to LCNF types erases expressions annotated with \lstinline|mdata|.
	\item The functions $\delta_{q_e}$ from \cref{sec:escapeanalysis} and $\gamma_{*_e}$ from \cref{sec:borrowing} need to be provided using a custom annotation in Lean 4's annotation mechanism, where declarations, including stubs for external functions and types, can be provided with auxiliary data by users.
	\item Lean's LCNF must be translated to our model IR and our model type system while preserving information about the mapping.
	\item Our type checker must be adjusted to produce reasonable error codes. As of now, it only yields a boolean indicating whether a given environment type-checks. Then, if there is a uniqueness type error, using the aforementioned mapping, the error for our model IR must be translated to a corresponding LCNF error.
	\item In addition to checking whether a given environment type-checks, our type checker must accumulate information about the scope in which a variable is unique. After translating this information back to LCNF, it can be used in subsequent optimizations, for example eliminating the reference count check described in \cref{sec:beans}.
\end{enumerate}

\section{Higher-Order Functions}
We have discussed the topic of higher-order functions in uniqueness type systems at length in \cref{sec:uniqueness} and \cref{sec:hof}, but chose to disregard uniqueness of functions for now in \cref{sec:types} by assuming every higher-order function as shared. 

This situation is far from optimal because Lean code uses higher-order functions for type classes, monadic code, as well as tricks that guarantee uniqueness for unique values within other unique values, like the \lstinline|update| trick discussed in \cref{sec:beans}. 

If we could use uniqueness annotations in type classes, defining the following classes that provide extra control over uniqueness would be possible:

\begin{code}
class Copyable (α) where
  copy : *α → *(*α × *α)
  
class LawfulCopyable (α) extends Copyable α where
  law : copy = (fun x => (x, x))
\end{code}

As discussed in \cref{sec:hof}, we believe that the approach that deleverages the uniqueness of objects in a function closure is the most viable, though it requires a change to the runtime in that higher-order functions need to store two function pointers as opposed to just one. Additionally, several other components in \cref{sec:theory} must be adjusted as well, as subtyping must now account for co- and contravariant type parameters and propagation must be capable of propagating through higher-order functions. Similarly, borrowing most be adjusted with unique functions in mind.

\section{Polymorphism}
Another topic we have not touched on at all is attribute polymorphism. Part of the reason for this is that polymorphism results in somewhat unintuitive behaviour if the coercion between unique and shared values is implicit, as in our system in \cref{sec:theory}, since polymorphic functions may both silently downcast a shared value and then propagate the sharedness through the rest of the code. In this case, using different function names would unveil the mistake early on.

However, if the coercion is made explicit, then mistakes would always be spotted early on, as a unique value can never be passed to a shared parameter unless users acknowledge it with an explicit instruction. Then, shared and unique functions would not need to be named differently, and polymorphism would be a useful thing to have.

What follows are some brief and incomplete thoughts on what would be required to make polymorphism work:
\begin{itemize}
	\item In order to be substitutable for both a unique and a shared attribute, variables that are polymorphic in their attribute can only be passed to polymorphic parameters, but must be used uniquely.
	\item Variables polymorphic in their attribute can be updated destructively.
	\item Borrowed parameters should always be shared, not polymorphic, since both linear and unique values can be passed to the parameter, but it is still allowed to share the parameter within the function body, as long as it does not escape.
	\item There needs to be a mechanism to connect the uniqueness of two attribute variables and state ``this component of the return type can be unique if this parameter is unique'', similar to Clean's $\leq$ operator or the boolean connectives discussed by \cite{vries_making_2009}.
	\item Uniqueness attributes in ADTs should propagate the attribute variable of the outer value when the respective field is accessed.
	\item Ideally, the fact that shared types cannot contain unique ones should not have to be explicitly reflected everywhere in the type annotation of a function; it should be assumed implicitly, or at least the annotational clutter that is present in de Vries' implementations of polymorphism should be reduced somehow.
\end{itemize}

An alternative to polymorphism would be to provide facilities that generate function declarations for all valid attribute annotations after monomorphization. Since there are only two attributes and users likely do not care much about the concrete uniqueness annotations except that they should make their code type check, generating functions for all possible annotations may be a worthwhile compromise, especially as systems that support attribute polymorphism tend to produce complex annotations that are difficult to grasp.

\section{Proof of Soundness}
In all of the previous sections, we have only argued informally about the soundness of our type system, i.e. that variables of unique type are indeed referenced uniquely. A formal proof of soundness of our system is still left to be done.